{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing requred libraries\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "1. Rank\n",
    "2. Name\n",
    "3. Artist\n",
    "4. Upload date\n",
    "5. Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['June 17, 2016', 'January 12, 2017', 'January 30, 2017', 'April 6, 2015', 'October 8, 2016', 'January 31, 2012', 'November 19, 2014', 'July 15, 2012', 'February 27, 2018', 'May 2, 2018', 'March 6, 2014', 'October 22, 2015', 'January 14, 2015', 'September 5, 2013', 'May 31, 2013', 'October 7, 2014', 'April 5, 2018', 'August 18, 2014', 'December 3, 2015', 'February 20, 2014', 'March 22, 2015', 'April 11, 2014', 'May 31, 2018', 'July 25, 2012', 'June 29, 2017', 'October 22, 2015', 'November 9, 2017', 'June 4, 2010', 'November 10, 2014', 'November 18, 2016', '7,037,500,000', 'June 17, 2016', 'November 2, 2020', '2,993,700,000', 'January 12, 2017', 'August 4, 2017', '2,894,000,000', 'April 6, 2015', 'July 10, 2017', '803,700,000', 'July 15, 2012', 'November 24, 2012', '245,400,000', 'February 19, 2010', 'July 16, 2010', '178,400,000', 'November 24, 2009', 'April 14, 2010', '128,900,000', 'May 22, 2007', 'October 25, 2009', '118,900,000', 'April 6, 2006', 'May 2, 2009', '92,600,000', 'February 27, 2007', 'July 17, 2008', '78,400,000', 'April 6, 2006', 'March 15, 2008', '76,600,000', 'April 9, 2007', 'March 1, 2008', '10,600,000', 'April 6, 2006', 'May 19, 2006', '4,300,000', 'November 28, 2005', 'March 12, 2006', '2,700,000', 'January 31, 2006', 'February 18, 2006', '3,400,000', 'December 1, 2005', 'January 21, 2006', '2,300,000', 'December 18, 2005', 'January 9, 2006', '255,000', 'October 21, 2005', 'October 31, 2005', '247,000', 'October 5, 2005', 'October 29, 2005', '1', 'April 23, 2005', 'April 23, 2005']\n"
     ]
    }
   ],
   "source": [
    "upl=[]\n",
    "up=driver.find_elements_by_xpath(\"//td[@align='right']\")\n",
    "for i in up:\n",
    "    text=i.text\n",
    "    upl.append(text)\n",
    "print(upl)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baby Shark Dance', 'Despacito', 'Shape of You', 'See You Again', 'Johny Johny Yes Papa', 'Mark Ronson', 'Psy', 'ChuChu TV', 'Justin Bieber', 'Maroon 5', 'Katy Perry', 'OneRepublic', 'Ed Sheeran', 'El Chombo', 'Taylor Swift', 'Alan Walker', 'Katy Perry', 'Major Lazer Official', 'Enrique Iglesias', 'Maroon 5', 'Passenger', 'J Balvin', 'Adele', 'Ed Sheeran', 'Shakira', 'Taylor Swift', 'Shakira', 'Me at the zoo', 'Life Goes On', 'Hurt']\n",
      "['Pinkfong', 'Luis Fonsi', 'Ed Sheeran', 'Wiz Khalifa', 'Uptown Funk', 'Gangnam Style', 'Cocomelon – Nursery Rhymes', 'Sorry', 'Sugar', 'Roar', 'Counting Stars', 'Thinking Out Loud', 'Dame Tu Cosita', 'Shake It Off', 'Faded', 'Dark Horse', 'Lean On', 'Bailando', 'Girls Like You', 'Let Her Go', 'Mi Gente', 'Hello', 'Perfect', 'Waka Waka (This Time for Africa)', 'Blank Space', 'Chantaje', 'Tarzan Boy', 'jawed', 'guitar', 'Galinha Pintadinha – videoclip infantil animado']\n"
     ]
    }
   ],
   "source": [
    "art=[]\n",
    "Artist=[]\n",
    "Name=[]\n",
    "a=driver.find_elements_by_xpath(\"//td/a\")\n",
    "for i in a:\n",
    "    text=i.text\n",
    "    art.append(text)\n",
    "Artist=art[0:60:2]\n",
    "Name=art[1:60:2]\n",
    "print(Artist)\n",
    "print(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.', '8.09', '[B]', '2.', '7.24', '[C]', '3.', '5.21', '[D]', '4.', '4.99', '[E]', '5.', '4.90', '[F]', '6.', '4.42', '[G]', '7.', '4.11', '[H]', '8.', '4.00', '[I]', '9.', '3.74', '10.', '3.74', '11.', '3.60', '12.', '3.41', '13.', '3.41', '14.', '3.29', '15.', '3.21', '16.', '3.20', '17.', '3.15', '18.', '3.03', '19.', '3.00', '20.', '2.99', '21.', '2.99', '22.', '2.98', '23.', '2.97', '24.', '2.93', '25.', '2.88', '26.', '2.80', '27.', '2.76', '28.', '2.76', '29.', '2.73', '30.', '2.63', '', '', '[113]', '[M]', '[27]', '[33]', '[N]', '[114]', '[O]', '93', '[117]', '[P]', '171', '[120]', '176', '[121]', '289', '[124]', '124', '[125]', '14', '[127]', '[Q]', '[130]', '[R]', '68', '[132]', '[S]', '22', '[137]', '28', '[139]', '[T]', '12', '[141]', '[143]', '[U]', '[146]', '[147]']\n"
     ]
    }
   ],
   "source": [
    "views=[]\n",
    "v=driver.find_elements_by_xpath(\"//td[@align='center']\")\n",
    "for i in v:\n",
    "    text=i.text\n",
    "    views.append(text)\n",
    "print(views)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.09',\n",
       " '7.24',\n",
       " '5.21',\n",
       " '4.99',\n",
       " '4.90',\n",
       " '4.42',\n",
       " '4.11',\n",
       " '4.00',\n",
       " '3.74',\n",
       " '11.',\n",
       " '3.41',\n",
       " '14.',\n",
       " '3.21',\n",
       " '17.',\n",
       " '3.03',\n",
       " '20.',\n",
       " '2.99',\n",
       " '23.',\n",
       " '2.93',\n",
       " '26.',\n",
       " '2.76',\n",
       " '29.',\n",
       " '2.63',\n",
       " '[113]',\n",
       " '[33]',\n",
       " '[O]',\n",
       " '[P]',\n",
       " '176',\n",
       " '[124]',\n",
       " '14',\n",
       " '[130]',\n",
       " '[132]',\n",
       " '[137]',\n",
       " '[T]',\n",
       " '[143]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view=[]\n",
    "view=views[1:-1:3]\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.', '11.', '12.', '13.', '14.', '15.', '16.', '17.', '18.', '19.', '20.', '21.', '22.', '23.', '24.', '25.', '26.', '27.', '28.', '29.', '30.']\n"
     ]
    }
   ],
   "source": [
    "rank=[]\n",
    "r=driver.find_elements_by_xpath(\"//td[1][@align='center']\")\n",
    "for i in r:\n",
    "    text=i.text\n",
    "    rank.append(text)\n",
    "print(rank)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                             Name  \\\n",
      "0    1.                                         Pinkfong   \n",
      "1    2.                                       Luis Fonsi   \n",
      "2    3.                                       Ed Sheeran   \n",
      "3    4.                                      Wiz Khalifa   \n",
      "4    5.                                      Uptown Funk   \n",
      "5    6.                                    Gangnam Style   \n",
      "6    7.                       Cocomelon – Nursery Rhymes   \n",
      "7    8.                                            Sorry   \n",
      "8    9.                                            Sugar   \n",
      "9   10.                                             Roar   \n",
      "10  11.                                   Counting Stars   \n",
      "11  12.                                Thinking Out Loud   \n",
      "12  13.                                   Dame Tu Cosita   \n",
      "13  14.                                     Shake It Off   \n",
      "14  15.                                            Faded   \n",
      "15  16.                                       Dark Horse   \n",
      "16  17.                                          Lean On   \n",
      "17  18.                                         Bailando   \n",
      "18  19.                                   Girls Like You   \n",
      "19  20.                                       Let Her Go   \n",
      "20  21.                                         Mi Gente   \n",
      "21  22.                                            Hello   \n",
      "22  23.                                          Perfect   \n",
      "23  24.                 Waka Waka (This Time for Africa)   \n",
      "24  25.                                      Blank Space   \n",
      "25  26.                                         Chantaje   \n",
      "26  27.                                       Tarzan Boy   \n",
      "27  28.                                            jawed   \n",
      "28  29.                                           guitar   \n",
      "29  30.  Galinha Pintadinha – videoclip infantil animado   \n",
      "\n",
      "                  Artist  Views  \n",
      "0       Baby Shark Dance   8.09  \n",
      "1              Despacito   7.24  \n",
      "2           Shape of You   5.21  \n",
      "3          See You Again   4.99  \n",
      "4   Johny Johny Yes Papa   4.90  \n",
      "5            Mark Ronson   4.42  \n",
      "6                    Psy   4.11  \n",
      "7              ChuChu TV   4.00  \n",
      "8          Justin Bieber   3.74  \n",
      "9               Maroon 5    11.  \n",
      "10            Katy Perry   3.41  \n",
      "11           OneRepublic    14.  \n",
      "12            Ed Sheeran   3.21  \n",
      "13             El Chombo    17.  \n",
      "14          Taylor Swift   3.03  \n",
      "15           Alan Walker    20.  \n",
      "16            Katy Perry   2.99  \n",
      "17  Major Lazer Official    23.  \n",
      "18      Enrique Iglesias   2.93  \n",
      "19              Maroon 5    26.  \n",
      "20             Passenger   2.76  \n",
      "21              J Balvin    29.  \n",
      "22                 Adele   2.63  \n",
      "23            Ed Sheeran  [113]  \n",
      "24               Shakira   [33]  \n",
      "25          Taylor Swift    [O]  \n",
      "26               Shakira    [P]  \n",
      "27         Me at the zoo    176  \n",
      "28          Life Goes On  [124]  \n",
      "29                  Hurt     14  \n"
     ]
    }
   ],
   "source": [
    "# create data frame\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Rank']=rank\n",
    "df['Name']=Name\n",
    "df['Artist']=Artist\n",
    "df['Views']=view[:30]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "1. Match title (I.e. 1st ODI)\n",
    "2. Series\n",
    "3. Place\n",
    "4. Date\n",
    "5. Time\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bcci.tv/international/fixtures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TEST', 'T20I', 'T20I', 'T20I', 'T20I', 'T20I', 'ODI', 'ODI', 'ODI', 'TEST', 'TEST', 'TEST', 'TEST', 'TEST']\n"
     ]
    }
   ],
   "source": [
    "match_title=[]\n",
    "mt=driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__format']\")\n",
    "for i in mt:\n",
    "    text=i.text\n",
    "    match_title.append(text)\n",
    "print(match_title)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INDIAvENGLAND', 'INDIAvENGLAND', 'INDIAvENGLAND', 'INDIAvENGLAND', 'INDIAvENGLAND', 'INDIAvENGLAND', 'INDIAvENGLAND', 'INDIAvENGLAND', 'INDIAvENGLAND', 'ENGLANDvINDIA', 'ENGLANDvINDIA', 'ENGLANDvINDIA', 'ENGLANDvINDIA', 'ENGLANDvINDIA']\n"
     ]
    }
   ],
   "source": [
    "series=[]\n",
    "S=driver.find_elements_by_xpath(\"//div[@class='fixture__teams']\")\n",
    "for i in S:\n",
    "    text=i.text\n",
    "    series.append(text.replace(\"\\n\",''))\n",
    "print(series)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thursday 04 MARCH 09:30 IST', 'Friday 12 MARCH 19:00 IST', 'Sunday 14 MARCH 19:00 IST', 'Tuesday 16 MARCH 19:00 IST', 'Thursday 18 MARCH 19:00 IST', 'Saturday 20 MARCH 19:00 IST', 'Tuesday 23 MARCH 13:30 IST', 'Friday 26 MARCH 13:30 IST', 'Sunday 28 MARCH 13:30 IST', 'Wednesday 04 AUGUST 15:30 IST', 'Thursday 12 AUGUST 15:30 IST', 'Wednesday 25 AUGUST 15:30 IST', 'Thursday 02 SEPTEMBER 15:30 IST', 'Friday 10 SEPTEMBER 15:30 IST']\n"
     ]
    }
   ],
   "source": [
    "date=[]\n",
    "d=driver.find_elements_by_xpath(\"//div[@class='fixture__datetime desktop-only']\")\n",
    "for i in d:\n",
    "    text=i.text\n",
    "    date.append(text.replace(\"\\n\",' '))\n",
    "print(date) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09:30 IST', '19:00 IST', '19:00 IST', '19:00 IST', '19:00 IST', '19:00 IST', '13:30 IST', '13:30 IST', '13:30 IST', '15:30 IST', '15:30 IST', '15:30 IST', '15:30 IST', '15:30 IST']\n"
     ]
    }
   ],
   "source": [
    "time=[]\n",
    "d=driver.find_elements_by_xpath(\"//span[@class='fixture__time']\")\n",
    "for i in d:\n",
    "    text=i.text\n",
    "    time.append(text)\n",
    "print(time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Narendra Modi Stadium, Ahmedabad', 'Narendra Modi Stadium, Ahmedabad', 'Narendra Modi Stadium, Ahmedabad', 'Narendra Modi Stadium, Ahmedabad', 'Narendra Modi Stadium, Ahmedabad', 'Narendra Modi Stadium, Ahmedabad', 'Maharashtra Cricket Association Stadium, Pune', 'Maharashtra Cricket Association Stadium, Pune', 'Maharashtra Cricket Association Stadium, Pune', 'Trent Bridge, Nottingham', \"Lord's, London\", 'Headingley, Leeds', 'The Oval, London', 'Old Trafford, Manchester']\n"
     ]
    }
   ],
   "source": [
    "place=[]\n",
    "d=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "for i in d:\n",
    "    text=i.text\n",
    "    place.append(text)\n",
    "print(place) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Match_Title         Series                             Date       Time  \\\n",
      "0         TEST  INDIAvENGLAND      Thursday 04 MARCH 09:30 IST  09:30 IST   \n",
      "1         T20I  INDIAvENGLAND        Friday 12 MARCH 19:00 IST  19:00 IST   \n",
      "2         T20I  INDIAvENGLAND        Sunday 14 MARCH 19:00 IST  19:00 IST   \n",
      "3         T20I  INDIAvENGLAND       Tuesday 16 MARCH 19:00 IST  19:00 IST   \n",
      "4         T20I  INDIAvENGLAND      Thursday 18 MARCH 19:00 IST  19:00 IST   \n",
      "5         T20I  INDIAvENGLAND      Saturday 20 MARCH 19:00 IST  19:00 IST   \n",
      "6          ODI  INDIAvENGLAND       Tuesday 23 MARCH 13:30 IST  13:30 IST   \n",
      "7          ODI  INDIAvENGLAND        Friday 26 MARCH 13:30 IST  13:30 IST   \n",
      "8          ODI  INDIAvENGLAND        Sunday 28 MARCH 13:30 IST  13:30 IST   \n",
      "9         TEST  ENGLANDvINDIA    Wednesday 04 AUGUST 15:30 IST  15:30 IST   \n",
      "10        TEST  ENGLANDvINDIA     Thursday 12 AUGUST 15:30 IST  15:30 IST   \n",
      "11        TEST  ENGLANDvINDIA    Wednesday 25 AUGUST 15:30 IST  15:30 IST   \n",
      "12        TEST  ENGLANDvINDIA  Thursday 02 SEPTEMBER 15:30 IST  15:30 IST   \n",
      "13        TEST  ENGLANDvINDIA    Friday 10 SEPTEMBER 15:30 IST  15:30 IST   \n",
      "\n",
      "                                            Place  \n",
      "0                Narendra Modi Stadium, Ahmedabad  \n",
      "1                Narendra Modi Stadium, Ahmedabad  \n",
      "2                Narendra Modi Stadium, Ahmedabad  \n",
      "3                Narendra Modi Stadium, Ahmedabad  \n",
      "4                Narendra Modi Stadium, Ahmedabad  \n",
      "5                Narendra Modi Stadium, Ahmedabad  \n",
      "6   Maharashtra Cricket Association Stadium, Pune  \n",
      "7   Maharashtra Cricket Association Stadium, Pune  \n",
      "8   Maharashtra Cricket Association Stadium, Pune  \n",
      "9                        Trent Bridge, Nottingham  \n",
      "10                                 Lord's, London  \n",
      "11                              Headingley, Leeds  \n",
      "12                               The Oval, London  \n",
      "13                       Old Trafford, Manchester  \n"
     ]
    }
   ],
   "source": [
    "# create data frame\n",
    "df=pd.DataFrame()\n",
    "df['Match_Title']=match_title\n",
    "df['Series']=series\n",
    "df['Date']=date\n",
    "df['Time']=time\n",
    "df['Place']=place\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of selenium exception from guru99.com.   Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "1. Name\n",
    "2. Description\n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.guru99.com/selenium-tutorial.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Name Description\n",
      "0                                                                \n",
      "1                                                                \n",
      "2                                                                \n",
      "3                                                        Tutorial\n",
      "4   What is Selenium? Introduction to Selenium Aut...    Tutorial\n",
      "..                                                ...         ...\n",
      "86                      20 BEST Selenium Alternatives    Tutorial\n",
      "87                       10 Best iMacros Alternatives    Tutorial\n",
      "88                Selenium Tutorial PDF: Download Now        Join\n",
      "89              Live Selenium Project: Banking Domain        Join\n",
      "90        Live Ecommerce Project: Selenium Automation            \n",
      "\n",
      "[91 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "descr=[]\n",
    "name=[]\n",
    "description=[]\n",
    "des=driver.find_elements_by_xpath(\"//tr/td\")\n",
    "for i in des:\n",
    "    text=i.text\n",
    "    descr.append(text)\n",
    "name=descr[0:-1:2]\n",
    "description=descr[1:-1:2]\n",
    "\n",
    "# create data frame\n",
    "df=pd.DataFrame()\n",
    "df['Name']=name\n",
    "df['Description']=description\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "1. Rank\n",
    "2. State\n",
    "3. GSDP(18-19)\n",
    "4. GSDP(17-18)\n",
    "5. Share(2017)\n",
    "6. GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://statisticstimes.com/economy/india/indian-states-gdp.php\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '']\n"
     ]
    }
   ],
   "source": [
    "rank=[]\n",
    "code=driver.find_elements_by_xpath(\"//td[@class='data1']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    rank.append(text)\n",
    "print(rank)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Gujarat', 'Karnataka', 'West Bengal', 'Rajasthan', 'Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Chhattisgarh', 'Jharkhand', 'Uttarakhand', 'Jammu & Kashmir', 'Himachal Pradesh', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Sikkim', 'Manipur', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India', 'Maharashtra', 'Tamil Nadu', 'Uttar Pradesh', 'Karnataka', 'Gujarat', 'West Bengal', 'Rajasthan', 'Telangana', 'Andhra Pradesh', 'Madhya Pradesh', 'Kerala', 'Delhi', 'Haryana', 'Bihar', 'Punjab', 'Odisha', 'Assam', 'Jharkhand', 'Chhattisgarh', 'Uttarakhand', 'Himachal Pradesh', 'Jammu & Kashmir', 'Goa', 'Tripura', 'Chandigarh', 'Puducherry', 'Meghalaya', 'Manipur', 'Sikkim', 'Nagaland', 'Arunachal Pradesh', 'Mizoram', 'Andaman & Nicobar Islands', 'India']\n"
     ]
    }
   ],
   "source": [
    "stats=[]\n",
    "code=driver.find_elements_by_xpath(\"//td[@class='name']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    stats.append(text)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2,632,792', '1,630,208', '1,584,764', '1,502,899', '1,493,127', '1,089,898', '942,586', '862,957', '861,031', '809,592', '781,653', '774,870', '734,163', '530,363', '526,376', '487,805', '315,881', '304,063', '297,204', '245,895', '155,956', '153,845', '73,170', '49,845', '42,114', '34,433', '33,481', '28,723', '27,870', '27,283', '24,603', '22,287', '-', '2,332,992', '1,465,361', '1,404,761', '1,351,553', '1,322,936', '995,502', '845,247', '782,370', '776,140', '737,156', '707,542', '704,529', '666,075', '486,776', '472,506', '428,031', '282,782', '271,990', '266,537', '221,871', '133,303', '129,877', '66,060', '44,835', '37,571', '31,415', '29,544', '25,323', '25,141', '24,534', '22,488', '20,947', '-']\n"
     ]
    }
   ],
   "source": [
    "gsdp_18_19=[]\n",
    "code=driver.find_elements_by_xpath(\"//td[@class='data sorting_1']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    gsdp_18_19.append(text)\n",
    "print(gsdp_18_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,845,853', '-', '1,253,832', '972,782', '906,672', '856,112', '611,804', '521,275', '329,180', '-', '165,472', '55,984', '38,253', '32,496', '-', '26,503', '1,659,210', '1,476,983', '1,150,711', '881,873', '827,019', '779,647', '562,710', '457,757', '301,242', '-', '-', '50,227', '34,823', '29,148', '-', '24,424']\n"
     ]
    }
   ],
   "source": [
    "gsdp_17_18=[]\n",
    "code=driver.find_elements_by_xpath(\"//tr[@class='even']/td[3]\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    gsdp_17_18.append(text)\n",
    "print(gsdp_17_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['246.529', '227.276', '164.820', '130.501', '122.431', '117.180', '80.204', '73.768', '45.982', '37.186', '23.265', '7.538', '5.207', '4.344', '4.126', '3.370', '1,167,776', '1,035,131', '713,376', '594,806', '496,798', '568,265', '377,276', '344,437', '218,232', '-', '-', '35,980', '22,291', '18,549', '-', '17,797']\n"
     ]
    }
   ],
   "source": [
    "gsdp_2017=[]\n",
    "code=driver.find_elements_by_xpath(\"//tr[@class='even']/td[6]\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    gsdp_2017.append(text)\n",
    "print(gsdp_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8.59%', '7.92%', '5.75%', '4.55%', '4.27%', '4.08%', '2.80%', '2.57%', '1.60%', '1.30%', '0.81%', '0.26%', '0.18%', '0.15%', '0.14%', '0.12%', '8.73%', '8.05%', '5.93%', '4.66%', '4.39%', '4.20%', '2.90%', '2.55%', '1.62%', '1.32%', '0.77%', '0.27%', '0.19%', '0.15%', '0.15%', '0.12%']\n"
     ]
    }
   ],
   "source": [
    "gdp=[]\n",
    "code=driver.find_elements_by_xpath(\"//tr[@class='even']/td[5]\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    gdp.append(text)\n",
    "print(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank             State GSDP(18-19) GDDP(17-18) Share(2017) GDP($billion)\n",
      "0     1       Maharashtra   2,632,792   1,845,853     246.529         8.59%\n",
      "1     2        Tamil Nadu   1,630,208           -     227.276         7.92%\n",
      "2     3     Uttar Pradesh   1,584,764   1,253,832     164.820         5.75%\n",
      "3     4           Gujarat   1,502,899     972,782     130.501         4.55%\n",
      "4     5         Karnataka   1,493,127     906,672     122.431         4.27%\n",
      "5     6       West Bengal   1,089,898     856,112     117.180         4.08%\n",
      "6     7         Rajasthan     942,586     611,804      80.204         2.80%\n",
      "7     8    Andhra Pradesh     862,957     521,275      73.768         2.57%\n",
      "8     9         Telangana     861,031     329,180      45.982         1.60%\n",
      "9    10    Madhya Pradesh     809,592           -      37.186         1.30%\n",
      "10   11            Kerala     781,653     165,472      23.265         0.81%\n",
      "11   12             Delhi     774,870      55,984       7.538         0.26%\n",
      "12   13           Haryana     734,163      38,253       5.207         0.18%\n",
      "13   14             Bihar     530,363      32,496       4.344         0.15%\n",
      "14   15            Punjab     526,376           -       4.126         0.14%\n",
      "15   16            Odisha     487,805      26,503       3.370         0.12%\n",
      "16   17             Assam     315,881   1,659,210   1,167,776         8.73%\n",
      "17   18      Chhattisgarh     304,063   1,476,983   1,035,131         8.05%\n",
      "18   19         Jharkhand     297,204   1,150,711     713,376         5.93%\n",
      "19   20       Uttarakhand     245,895     881,873     594,806         4.66%\n",
      "20   21   Jammu & Kashmir     155,956     827,019     496,798         4.39%\n",
      "21   22  Himachal Pradesh     153,845     779,647     568,265         4.20%\n",
      "22   23               Goa      73,170     562,710     377,276         2.90%\n",
      "23   24           Tripura      49,845     457,757     344,437         2.55%\n",
      "24   25        Chandigarh      42,114     301,242     218,232         1.62%\n",
      "25   26        Puducherry      34,433           -           -         1.32%\n",
      "26   27         Meghalaya      33,481           -           -         0.77%\n",
      "27   28            Sikkim      28,723      50,227      35,980         0.27%\n",
      "28   29           Manipur      27,870      34,823      22,291         0.19%\n",
      "29   30          Nagaland      27,283      29,148      18,549         0.15%\n"
     ]
    }
   ],
   "source": [
    "#create dataframe\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Rank']=rank[:30]\n",
    "df['State']=stats[:30]\n",
    "df['GSDP(18-19)']=gsdp_18_19[:30]\n",
    "df['GDDP(17-18)']=gsdp_17_18[:30]\n",
    "df['Share(2017)']=gsdp_2017[:30]\n",
    "df['GDP($billion)']=gdp[:30]\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "1. Repository title\n",
    "2. Repository description\n",
    "3. Contributors count\n",
    "4. Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/search?q=top+repository')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OWASP/Top10', 'RobThree/MongoRepository', 'mbadry1/Top-Deep-Learning', 'trinker/topicmodels_learning', 'spring-projects/spring-data-rest', 'csdms-contrib/topotoolbox', 'black-shadows/InterviewBit-Topicwise-Solutions', 'mmazzarolo/top-github', 'larsmaaloee/deep-belief-nets-for-topic-modeling', 'ExpediaDotCom/haystack']\n"
     ]
    }
   ],
   "source": [
    "rep_title=[]\n",
    "code=driver.find_elements_by_xpath(\"//a[@class='v-align-middle']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    rep_title.append(text)\n",
    "print(rep_title)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Official OWASP Top 10 Document Repository', 'Repository abstraction layer on top of Official MongoDB C# driver', 'Top 200 deep learning Github repositories sorted by the number of stars.', 'A repository of learning & R resources related to topic models', 'Simplifies building hypermedia-driven REST web services on top of Spring Data repositories', 'This repository contains the latest release. A newer pre-release version is available at wschwanghart/topotoolbox', 'The repository contains solutions to various problems on interviewbit. The code is merely a snippet (as solved on Int…', 'Android app for browsing GitHub top repositories', 'This repository is a proof of concept toolbox for using Deep Belief Nets for Topic Modeling in Python.', 'Top level repository for Haystack, containing documentation and deployment scripts']\n"
     ]
    }
   ],
   "source": [
    "rep_des=[]\n",
    "code=driver.find_elements_by_xpath(\"//p[@class='mb-1']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    rep_des.append(text.replace('\\n',' '))\n",
    "print(rep_des) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.7k', '290', '1.4k', '200', '739', '20', '142', '94', '144', '260']\n"
     ]
    }
   ],
   "source": [
    "count=[]\n",
    "code=driver.find_elements_by_xpath(\"//a[@class='Link--muted']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    count.append(text)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HTML', 'C#', 'Python', 'R', 'Java', 'HTML', 'C++', 'Java', 'Python', 'HCL']\n"
     ]
    }
   ],
   "source": [
    "lang=[]\n",
    "language=[]\n",
    "code=driver.find_elements_by_xpath(\"//div[@class='mr-3']/span\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    lang.append(text)\n",
    "print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Repository_Title  \\\n",
      "0                                      OWASP/Top10   \n",
      "1                         RobThree/MongoRepository   \n",
      "2                        mbadry1/Top-Deep-Learning   \n",
      "3                     trinker/topicmodels_learning   \n",
      "4                 spring-projects/spring-data-rest   \n",
      "5                        csdms-contrib/topotoolbox   \n",
      "6   black-shadows/InterviewBit-Topicwise-Solutions   \n",
      "7                            mmazzarolo/top-github   \n",
      "8  larsmaaloee/deep-belief-nets-for-topic-modeling   \n",
      "9                           ExpediaDotCom/haystack   \n",
      "\n",
      "                              Repository_Description Contributors_count  \\\n",
      "0          Official OWASP Top 10 Document Repository               1.7k   \n",
      "1  Repository abstraction layer on top of Officia...                290   \n",
      "2  Top 200 deep learning Github repositories sort...               1.4k   \n",
      "3  A repository of learning & R resources related...                200   \n",
      "4  Simplifies building hypermedia-driven REST web...                739   \n",
      "5  This repository contains the latest release. A...                 20   \n",
      "6  The repository contains solutions to various p...                142   \n",
      "7   Android app for browsing GitHub top repositories                 94   \n",
      "8  This repository is a proof of concept toolbox ...                144   \n",
      "9  Top level repository for Haystack, containing ...                260   \n",
      "\n",
      "  Language_Used  \n",
      "0          HTML  \n",
      "1            C#  \n",
      "2        Python  \n",
      "3             R  \n",
      "4          Java  \n",
      "5          HTML  \n",
      "6           C++  \n",
      "7          Java  \n",
      "8        Python  \n",
      "9           HCL  \n"
     ]
    }
   ],
   "source": [
    "# create dataframe\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Repository_Title']=rep_title\n",
    "df['Repository_Description']=rep_des\n",
    "df['Contributors_count']=count\n",
    "df['Language_Used']=lang\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "1. Name\n",
    "2. Designation\n",
    "3. Company\n",
    "4. Skills they hire for\n",
    "5. Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com/data-science-jobs?k=data%20science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science Developer',\n",
       " 'Senior Data Science Engineer',\n",
       " 'Data Science Lead - Marketing Analytics',\n",
       " 'Data Science/ Analysis Expert - Machine Learning',\n",
       " 'QA Data Science Intern',\n",
       " 'Freshers - Data Science/ Machine Learning/ Analytics/ AI',\n",
       " 'Freshers - Data Science/ Machine Learning/ AI',\n",
       " 'Lead Python (Data Science) Engineer',\n",
       " 'Analyst - Data Science / Data Scientist | Client of Ruboid | Gurgaon',\n",
       " 'Analyst - Data Science / Data Scientist | Client of Ruboid | Gurgaon',\n",
       " 'Freshers - Data Science/ Machine Learning/ AI/Analytics',\n",
       " 'Data Science Lead',\n",
       " 'Data Science Lead',\n",
       " 'Data Science Platform Lead',\n",
       " 'Data Science Platform Lead',\n",
       " 'Data Science Analyst -Forecasting',\n",
       " 'Data Science - Fresher',\n",
       " 'Data Science - Fresher',\n",
       " 'Senior Data Science & Analytics Platform Engineer',\n",
       " 'Data Science']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "code=driver.find_elements_by_xpath(\"//div[@class='info fleft']/a\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    name.append(text)\n",
    "name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Birlasoft',\n",
       " 'NetApp',\n",
       " 'AugmatrixGo',\n",
       " 'Catalyst',\n",
       " 'ALTAIR DEVELOPERS PRIVATE LIMITED',\n",
       " 'CHANDRA PUMPS',\n",
       " 'Aahana',\n",
       " 'Tide Software',\n",
       " 'RUBOID TECHNOVISION PRIVATE LIMITED',\n",
       " 'RUBOID TECHNOVISION PRIVATE LIMITED',\n",
       " 'Aahana',\n",
       " 'NatWest Markets',\n",
       " 'NatWest Group',\n",
       " 'NatWest Markets',\n",
       " 'NatWest Group',\n",
       " 'Pattern',\n",
       " 'KREATE ENERGY (I) PRIVATE LIMITED',\n",
       " 'KREATE ENERGY (I) PRIVATE LIMITED',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'Capgemini Technology Services India Limited']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company=[]\n",
    "code=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    company.append(text)\n",
    "company    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hands on experience in RUL model, XGBoost and other tree-based modelsBachelors in IT/ s...',\n",
       " 'Bachelors degree in Data Science, Statistics, Computer Science, or similarKey Qualifica...',\n",
       " 'Understanding of web analytics and digital marketing are a mustTechnical Skills : - Web...',\n",
       " 'Job Requirements : - BTech From Tier 1 Institute OR BSTAT & MSTAT From ISI OR Masters i...',\n",
       " 'Ability to manage multiple assignments simultaneously and shift priorities as neededWe ...',\n",
       " 'Looking for candidates who are passionate about to start a career in Data Science. Grad...',\n",
       " 'Candidates willing to make their career in Data Science. Candidate should have good ana...',\n",
       " 'About You You are enthusiastic about using data technology to solve business problems. ...',\n",
       " 'Roles and Responsibilities Greetings from Ruboid!!This is with regards to an excellent ...',\n",
       " 'Roles and Responsibilities Greetings from Ruboid!!This is with regards to an excellent ...',\n",
       " 'Candidates willing to make their career in Data Science. Candidate should have good ana...',\n",
       " 'Experience designing and building end-to-end machine learning based pipelines Experienc...',\n",
       " 'Experience designing and building end-to-end machine learning based pipelines Experienc...',\n",
       " 'Experience designing and building end-to-end machine learning based pipelines Experienc...',\n",
       " 'Experience designing and building end-to-end machine learning based pipelines Experienc...',\n",
       " 'Associate or Bachelors degree in Computer Science, Math, Statistics, Logistics, or clos...',\n",
       " 'Academic qualification: Graduation / Post Graduation (BSc / MSc in Maths or Statistics)...',\n",
       " 'Academic qualification: Graduation / Post Graduation (BSc / MSc in Maths or Statistics)...',\n",
       " 'If you are ready for an exciting career YOU would be responsible for the following.Are ...',\n",
       " 'SAS, SPSS, Matlab are also preferred Working experience in various other data science t...']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill=[]\n",
    "code=driver.find_elements_by_xpath(\"//div[@class='job-description fs12 grey-text']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    skill.append(text)\n",
    "skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4-9 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Pune',\n",
       " '7-12 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '5-10 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram',\n",
       " '2-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '0-1 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '0-5 Yrs',\n",
       " '3,00,000 - 4,00,000 PA.',\n",
       " 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru',\n",
       " '0-5 Yrs',\n",
       " '3,00,000 - 4,00,000 PA.',\n",
       " 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru',\n",
       " '0-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Hyderabad/Secunderabad',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Gurgaon/Gurugram',\n",
       " '3-5 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Gurgaon/Gurugram',\n",
       " '0-5 Yrs',\n",
       " '3,00,000 - 4,00,000 PA.',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " '3-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-7 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-7 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '3-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Pune',\n",
       " '0-0 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Delhi / NCR',\n",
       " '0-0 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Delhi / NCR',\n",
       " '4-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru',\n",
       " '4-6 Yrs',\n",
       " 'Not disclosed',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc=[]\n",
    "code=driver.find_elements_by_xpath(\"//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    loc.append(text)\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pune',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune',\n",
       " 'Delhi / NCR',\n",
       " 'Delhi / NCR',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=loc[2:-1:3]\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Developer</td>\n",
       "      <td>Data Science Developer</td>\n",
       "      <td>Birlasoft</td>\n",
       "      <td>Hands on experience in RUL model, XGBoost and ...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Bachelors degree in Data Science, Statistics, ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Lead - Marketing Analytics</td>\n",
       "      <td>Data Science Lead - Marketing Analytics</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Understanding of web analytics and digital mar...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science/ Analysis Expert - Machine Learning</td>\n",
       "      <td>Data Science/ Analysis Expert - Machine Learning</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>Job Requirements : - BTech From Tier 1 Institu...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QA Data Science Intern</td>\n",
       "      <td>QA Data Science Intern</td>\n",
       "      <td>ALTAIR DEVELOPERS PRIVATE LIMITED</td>\n",
       "      <td>Ability to manage multiple assignments simulta...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Freshers - Data Science/ Machine Learning/ Ana...</td>\n",
       "      <td>Freshers - Data Science/ Machine Learning/ Ana...</td>\n",
       "      <td>CHANDRA PUMPS</td>\n",
       "      <td>Looking for candidates who are passionate abou...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Freshers - Data Science/ Machine Learning/ AI</td>\n",
       "      <td>Freshers - Data Science/ Machine Learning/ AI</td>\n",
       "      <td>Aahana</td>\n",
       "      <td>Candidates willing to make their career in Dat...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Python (Data Science) Engineer</td>\n",
       "      <td>Lead Python (Data Science) Engineer</td>\n",
       "      <td>Tide Software</td>\n",
       "      <td>About You You are enthusiastic about using dat...</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Analyst - Data Science / Data Scientist | Clie...</td>\n",
       "      <td>Analyst - Data Science / Data Scientist | Clie...</td>\n",
       "      <td>RUBOID TECHNOVISION PRIVATE LIMITED</td>\n",
       "      <td>Roles and Responsibilities Greetings from Rubo...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Analyst - Data Science / Data Scientist | Clie...</td>\n",
       "      <td>Analyst - Data Science / Data Scientist | Clie...</td>\n",
       "      <td>RUBOID TECHNOVISION PRIVATE LIMITED</td>\n",
       "      <td>Roles and Responsibilities Greetings from Rubo...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Freshers - Data Science/ Machine Learning/ AI/...</td>\n",
       "      <td>Freshers - Data Science/ Machine Learning/ AI/...</td>\n",
       "      <td>Aahana</td>\n",
       "      <td>Candidates willing to make their career in Dat...</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Science Lead</td>\n",
       "      <td>Data Science Lead</td>\n",
       "      <td>NatWest Markets</td>\n",
       "      <td>Experience designing and building end-to-end m...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Science Lead</td>\n",
       "      <td>Data Science Lead</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>Experience designing and building end-to-end m...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Science Platform Lead</td>\n",
       "      <td>Data Science Platform Lead</td>\n",
       "      <td>NatWest Markets</td>\n",
       "      <td>Experience designing and building end-to-end m...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Science Platform Lead</td>\n",
       "      <td>Data Science Platform Lead</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>Experience designing and building end-to-end m...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Science Analyst -Forecasting</td>\n",
       "      <td>Data Science Analyst -Forecasting</td>\n",
       "      <td>Pattern</td>\n",
       "      <td>Associate or Bachelors degree in Computer Scie...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Science - Fresher</td>\n",
       "      <td>Data Science - Fresher</td>\n",
       "      <td>KREATE ENERGY (I) PRIVATE LIMITED</td>\n",
       "      <td>Academic qualification: Graduation / Post Grad...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Science - Fresher</td>\n",
       "      <td>Data Science - Fresher</td>\n",
       "      <td>KREATE ENERGY (I) PRIVATE LIMITED</td>\n",
       "      <td>Academic qualification: Graduation / Post Grad...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Data Science &amp; Analytics Platform Engineer</td>\n",
       "      <td>Senior Data Science &amp; Analytics Platform Engineer</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>If you are ready for an exciting career YOU wo...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0                              Data Science Developer   \n",
       "1                        Senior Data Science Engineer   \n",
       "2             Data Science Lead - Marketing Analytics   \n",
       "3    Data Science/ Analysis Expert - Machine Learning   \n",
       "4                              QA Data Science Intern   \n",
       "5   Freshers - Data Science/ Machine Learning/ Ana...   \n",
       "6       Freshers - Data Science/ Machine Learning/ AI   \n",
       "7                 Lead Python (Data Science) Engineer   \n",
       "8   Analyst - Data Science / Data Scientist | Clie...   \n",
       "9   Analyst - Data Science / Data Scientist | Clie...   \n",
       "10  Freshers - Data Science/ Machine Learning/ AI/...   \n",
       "11                                  Data Science Lead   \n",
       "12                                  Data Science Lead   \n",
       "13                         Data Science Platform Lead   \n",
       "14                         Data Science Platform Lead   \n",
       "15                  Data Science Analyst -Forecasting   \n",
       "16                             Data Science - Fresher   \n",
       "17                             Data Science - Fresher   \n",
       "18  Senior Data Science & Analytics Platform Engineer   \n",
       "\n",
       "                                          Designation  \\\n",
       "0                              Data Science Developer   \n",
       "1                        Senior Data Science Engineer   \n",
       "2             Data Science Lead - Marketing Analytics   \n",
       "3    Data Science/ Analysis Expert - Machine Learning   \n",
       "4                              QA Data Science Intern   \n",
       "5   Freshers - Data Science/ Machine Learning/ Ana...   \n",
       "6       Freshers - Data Science/ Machine Learning/ AI   \n",
       "7                 Lead Python (Data Science) Engineer   \n",
       "8   Analyst - Data Science / Data Scientist | Clie...   \n",
       "9   Analyst - Data Science / Data Scientist | Clie...   \n",
       "10  Freshers - Data Science/ Machine Learning/ AI/...   \n",
       "11                                  Data Science Lead   \n",
       "12                                  Data Science Lead   \n",
       "13                         Data Science Platform Lead   \n",
       "14                         Data Science Platform Lead   \n",
       "15                  Data Science Analyst -Forecasting   \n",
       "16                             Data Science - Fresher   \n",
       "17                             Data Science - Fresher   \n",
       "18  Senior Data Science & Analytics Platform Engineer   \n",
       "\n",
       "                                    Company  \\\n",
       "0                                 Birlasoft   \n",
       "1                                    NetApp   \n",
       "2                               AugmatrixGo   \n",
       "3                                  Catalyst   \n",
       "4         ALTAIR DEVELOPERS PRIVATE LIMITED   \n",
       "5                             CHANDRA PUMPS   \n",
       "6                                    Aahana   \n",
       "7                             Tide Software   \n",
       "8       RUBOID TECHNOVISION PRIVATE LIMITED   \n",
       "9       RUBOID TECHNOVISION PRIVATE LIMITED   \n",
       "10                                   Aahana   \n",
       "11                          NatWest Markets   \n",
       "12                            NatWest Group   \n",
       "13                          NatWest Markets   \n",
       "14                            NatWest Group   \n",
       "15                                  Pattern   \n",
       "16        KREATE ENERGY (I) PRIVATE LIMITED   \n",
       "17        KREATE ENERGY (I) PRIVATE LIMITED   \n",
       "18  GlaxoSmithKline Pharmaceuticals Limited   \n",
       "\n",
       "                                                Skill  \\\n",
       "0   Hands on experience in RUL model, XGBoost and ...   \n",
       "1   Bachelors degree in Data Science, Statistics, ...   \n",
       "2   Understanding of web analytics and digital mar...   \n",
       "3   Job Requirements : - BTech From Tier 1 Institu...   \n",
       "4   Ability to manage multiple assignments simulta...   \n",
       "5   Looking for candidates who are passionate abou...   \n",
       "6   Candidates willing to make their career in Dat...   \n",
       "7   About You You are enthusiastic about using dat...   \n",
       "8   Roles and Responsibilities Greetings from Rubo...   \n",
       "9   Roles and Responsibilities Greetings from Rubo...   \n",
       "10  Candidates willing to make their career in Dat...   \n",
       "11  Experience designing and building end-to-end m...   \n",
       "12  Experience designing and building end-to-end m...   \n",
       "13  Experience designing and building end-to-end m...   \n",
       "14  Experience designing and building end-to-end m...   \n",
       "15  Associate or Bachelors degree in Computer Scie...   \n",
       "16  Academic qualification: Graduation / Post Grad...   \n",
       "17  Academic qualification: Graduation / Post Grad...   \n",
       "18  If you are ready for an exciting career YOU wo...   \n",
       "\n",
       "                                             Location  \n",
       "0                                                Pune  \n",
       "1                                 Bangalore/Bengaluru  \n",
       "2      Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram  \n",
       "3                                 Bangalore/Bengaluru  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5   Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru  \n",
       "6   Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru  \n",
       "7                              Hyderabad/Secunderabad  \n",
       "8                                    Gurgaon/Gurugram  \n",
       "9                                    Gurgaon/Gurugram  \n",
       "10  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...  \n",
       "11                                Bangalore/Bengaluru  \n",
       "12                                Bangalore/Bengaluru  \n",
       "13                                Bangalore/Bengaluru  \n",
       "14                                Bangalore/Bengaluru  \n",
       "15                                               Pune  \n",
       "16                                        Delhi / NCR  \n",
       "17                                        Delhi / NCR  \n",
       "18                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "df=pd.DataFrame()\n",
    "df['Name']=name[:19]\n",
    "df[\"Designation\"]=name[:19]\n",
    "df['Company']=company[:19]\n",
    "df['Skill']=skill[:19]\n",
    "df['Location']=location[:19]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "You have to find the following details:\n",
    "1. Book name\n",
    "2. Author name\n",
    "3. Volumes sold\n",
    "4. Publisher\n",
    "5. Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry Potter and the Deathly Hallows',\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Twilight',\n",
       " 'Fifty Shades Freed',\n",
       " 'New Moon',\n",
       " 'Eclipse',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Breaking Dawn',\n",
       " 'Gruffalo,The',\n",
       " 'Kite Runner,The',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Time Traveler's Wife,The\",\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Life of Pi',\n",
       " 'Child Called It,A',\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Man and Boy',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'PS, I Love You',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Broker,The',\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Lord of the Rings,The',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " 'Notes from a Small Island',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " 'I Can Make You Thin',\n",
       " 'Summons,The',\n",
       " 'Nigella Express',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'About a Boy',\n",
       " 'God Delusion,The',\n",
       " 'White Teeth',\n",
       " 'Book Thief,The',\n",
       " 'Ghost,The',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_name=[]\n",
    "code=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[2]\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    b_name.append(text)\n",
    "b_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Meyer, Stephenie',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Meyer, Stephenie',\n",
       " 'Haddon, Mark',\n",
       " 'Bryson, Bill',\n",
       " 'Meyer, Stephenie',\n",
       " 'Donaldson, Julia',\n",
       " 'Hosseini, Khaled',\n",
       " 'Hosseini, Khaled',\n",
       " 'Niffenegger, Audrey',\n",
       " 'Fielding, Helen',\n",
       " 'Bernieres, Louis de',\n",
       " 'Martel, Yann',\n",
       " 'Pelzer, Dave',\n",
       " 'McCourt, Frank',\n",
       " 'Pullman, Philip',\n",
       " 'Rowling, J.K.',\n",
       " 'Parsons, Tony',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Ahern, Cecelia',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Grisham, John',\n",
       " 'Pullman, Philip',\n",
       " 'Smith, Delia',\n",
       " 'Boyne, John',\n",
       " 'Pullman, Philip',\n",
       " 'Gray, John',\n",
       " 'Lewycka, Marina',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Coelho, Paulo',\n",
       " 'Bryson, Bill',\n",
       " 'Fielding, Helen',\n",
       " 'McKenna, Paul',\n",
       " 'Grisham, John',\n",
       " 'Lawson, Nigella',\n",
       " 'Edwards, Kim',\n",
       " 'Hornby, Nick',\n",
       " 'Dawkins, Richard',\n",
       " 'Smith, Zadie',\n",
       " 'Zusak, Markus',\n",
       " 'Harris, Robert',\n",
       " 'Collins, Suzanne',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author=[]\n",
    "code=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[3]\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    author.append(text)\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4,475,152',\n",
       " '4,179,479',\n",
       " '3,583,215',\n",
       " '3,377,906',\n",
       " '2,950,264',\n",
       " '2,315,405',\n",
       " '2,193,928',\n",
       " '2,152,737',\n",
       " '2,052,876',\n",
       " '1,979,552',\n",
       " '1,852,919',\n",
       " '1,787,118',\n",
       " '1,781,269',\n",
       " '1,629,119',\n",
       " '1,583,992',\n",
       " '1,546,886',\n",
       " '1,508,205',\n",
       " '1,352,318',\n",
       " '1,310,176',\n",
       " '1,217,712',\n",
       " '1,204,058',\n",
       " '1,181,503',\n",
       " '1,153,181',\n",
       " '1,130,802',\n",
       " '1,115,549',\n",
       " '1,107,379',\n",
       " '1,092,349',\n",
       " '1,087,262',\n",
       " '1,037,160',\n",
       " '1,015,956',\n",
       " '1,004,414',\n",
       " '1,002,314',\n",
       " '992,846',\n",
       " '986,115',\n",
       " '967,466',\n",
       " '962,515',\n",
       " '956,114',\n",
       " '931,312',\n",
       " '924,695',\n",
       " '905,086',\n",
       " '869,671',\n",
       " '862,602',\n",
       " '845,858',\n",
       " '828,215',\n",
       " '816,907',\n",
       " '815,586',\n",
       " '809,641',\n",
       " '807,311',\n",
       " '792,187',\n",
       " '791,095']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sold=[]\n",
    "code=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[4]\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    sold.append(text)\n",
    "sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Little, Brown Book',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Little, Brown Book',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'Orion',\n",
       " 'HarperCollins',\n",
       " 'Scholastic Ltd.',\n",
       " 'Bloomsbury',\n",
       " 'HarperCollins',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'Random House Childrens Books G',\n",
       " 'Scholastic Ltd.',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publisher=[]\n",
    "code=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[5]\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    publisher.append(text)\n",
    "publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Young Adult Fiction',\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Science',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'Autobiography: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Travel Writing',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Science',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre=[]\n",
    "code=driver.find_elements_by_xpath(\"//tr[@class='odd']/td[6]\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    genre.append(text)\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,583,215</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,377,906</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Half-blood Prince:Childre...</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>2,950,264</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,315,405</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fifty Shades Freed</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,193,928</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New Moon</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,152,737</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Eclipse</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,052,876</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Curious Incident of the Dog in the Night-time,The</td>\n",
       "      <td>Haddon, Mark</td>\n",
       "      <td>1,979,552</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Short History of Nearly Everything,A</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>1,852,919</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Popular Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Breaking Dawn</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>1,787,118</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gruffalo,The</td>\n",
       "      <td>Donaldson, Julia</td>\n",
       "      <td>1,781,269</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kite Runner,The</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,629,119</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Thousand Splendid Suns,A</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,583,992</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Time Traveler's Wife,The</td>\n",
       "      <td>Niffenegger, Audrey</td>\n",
       "      <td>1,546,886</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bridget Jones's Diary:A Novel</td>\n",
       "      <td>Fielding, Helen</td>\n",
       "      <td>1,508,205</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Captain Corelli's Mandolin</td>\n",
       "      <td>Bernieres, Louis de</td>\n",
       "      <td>1,352,318</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Life of Pi</td>\n",
       "      <td>Martel, Yann</td>\n",
       "      <td>1,310,176</td>\n",
       "      <td>Canongate</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Child Called It,A</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>1,217,712</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Autobiography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Angela's Ashes:A Memoir of a Childhood</td>\n",
       "      <td>McCourt, Frank</td>\n",
       "      <td>1,204,058</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Autobiography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Northern Lights:His Dark Materials S.</td>\n",
       "      <td>Pullman, Philip</td>\n",
       "      <td>1,181,503</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Harry Potter and the Half-blood Prince</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>1,153,181</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Man and Boy</td>\n",
       "      <td>Parsons, Tony</td>\n",
       "      <td>1,130,802</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>No.1 Ladies' Detective Agency,The:No.1 Ladies'...</td>\n",
       "      <td>McCall Smith, Alexander</td>\n",
       "      <td>1,115,549</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PS, I Love You</td>\n",
       "      <td>Ahern, Cecelia</td>\n",
       "      <td>1,107,379</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shadow of the Wind,The</td>\n",
       "      <td>Zafon, Carlos Ruiz</td>\n",
       "      <td>1,092,349</td>\n",
       "      <td>Orion</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Broker,The</td>\n",
       "      <td>Grisham, John</td>\n",
       "      <td>1,087,262</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Subtle Knife,The:His Dark Materials S.</td>\n",
       "      <td>Pullman, Philip</td>\n",
       "      <td>1,037,160</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Delia's How to Cook:(Bk.1)</td>\n",
       "      <td>Smith, Delia</td>\n",
       "      <td>1,015,956</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Boy in the Striped Pyjamas,The</td>\n",
       "      <td>Boyne, John</td>\n",
       "      <td>1,004,414</td>\n",
       "      <td>Random House Childrens Books G</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amber Spyglass,The:His Dark Materials S.</td>\n",
       "      <td>Pullman, Philip</td>\n",
       "      <td>1,002,314</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Men are from Mars, Women are from Venus:A Prac...</td>\n",
       "      <td>Gray, John</td>\n",
       "      <td>992,846</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Popular Culture &amp; Media: General Interest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Short History of Tractors in Ukrainian,A</td>\n",
       "      <td>Lewycka, Marina</td>\n",
       "      <td>986,115</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lord of the Rings,The</td>\n",
       "      <td>Tolkien, J. R. R.</td>\n",
       "      <td>967,466</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Interpretation of Murder,The</td>\n",
       "      <td>Rubenfeld, Jed</td>\n",
       "      <td>962,515</td>\n",
       "      <td>Headline</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Alchemist,The:A Fable About Following Your Dream</td>\n",
       "      <td>Coelho, Paulo</td>\n",
       "      <td>956,114</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Notes from a Small Island</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>931,312</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Travel Writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bridget Jones: The Edge of Reason</td>\n",
       "      <td>Fielding, Helen</td>\n",
       "      <td>924,695</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I Can Make You Thin</td>\n",
       "      <td>McKenna, Paul</td>\n",
       "      <td>905,086</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Fitness &amp; Diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Summons,The</td>\n",
       "      <td>Grisham, John</td>\n",
       "      <td>869,671</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Nigella Express</td>\n",
       "      <td>Lawson, Nigella</td>\n",
       "      <td>862,602</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Memory Keeper's Daughter,The</td>\n",
       "      <td>Edwards, Kim</td>\n",
       "      <td>845,858</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>About a Boy</td>\n",
       "      <td>Hornby, Nick</td>\n",
       "      <td>828,215</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>God Delusion,The</td>\n",
       "      <td>Dawkins, Richard</td>\n",
       "      <td>816,907</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Popular Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>White Teeth</td>\n",
       "      <td>Smith, Zadie</td>\n",
       "      <td>815,586</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Book Thief,The</td>\n",
       "      <td>Zusak, Markus</td>\n",
       "      <td>809,641</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name  \\\n",
       "0                Harry Potter and the Deathly Hallows   \n",
       "1           Harry Potter and the Order of the Phoenix   \n",
       "2                 Harry Potter and the Goblet of Fire   \n",
       "3            Harry Potter and the Prisoner of Azkaban   \n",
       "4   Harry Potter and the Half-blood Prince:Childre...   \n",
       "5                                            Twilight   \n",
       "6                                  Fifty Shades Freed   \n",
       "7                                            New Moon   \n",
       "8                                             Eclipse   \n",
       "9   Curious Incident of the Dog in the Night-time,The   \n",
       "10               Short History of Nearly Everything,A   \n",
       "11                                      Breaking Dawn   \n",
       "12                                       Gruffalo,The   \n",
       "13                                    Kite Runner,The   \n",
       "14                           Thousand Splendid Suns,A   \n",
       "15                           Time Traveler's Wife,The   \n",
       "16                      Bridget Jones's Diary:A Novel   \n",
       "17                         Captain Corelli's Mandolin   \n",
       "18                                         Life of Pi   \n",
       "19                                  Child Called It,A   \n",
       "20             Angela's Ashes:A Memoir of a Childhood   \n",
       "21              Northern Lights:His Dark Materials S.   \n",
       "22             Harry Potter and the Half-blood Prince   \n",
       "23                                        Man and Boy   \n",
       "24  No.1 Ladies' Detective Agency,The:No.1 Ladies'...   \n",
       "25                                     PS, I Love You   \n",
       "26                             Shadow of the Wind,The   \n",
       "27                                         Broker,The   \n",
       "28             Subtle Knife,The:His Dark Materials S.   \n",
       "29                         Delia's How to Cook:(Bk.1)   \n",
       "30                     Boy in the Striped Pyjamas,The   \n",
       "31           Amber Spyglass,The:His Dark Materials S.   \n",
       "32  Men are from Mars, Women are from Venus:A Prac...   \n",
       "33           Short History of Tractors in Ukrainian,A   \n",
       "34                              Lord of the Rings,The   \n",
       "35                       Interpretation of Murder,The   \n",
       "36   Alchemist,The:A Fable About Following Your Dream   \n",
       "37                          Notes from a Small Island   \n",
       "38                  Bridget Jones: The Edge of Reason   \n",
       "39                                I Can Make You Thin   \n",
       "40                                        Summons,The   \n",
       "41                                    Nigella Express   \n",
       "42                       Memory Keeper's Daughter,The   \n",
       "43                                        About a Boy   \n",
       "44                                   God Delusion,The   \n",
       "45                                        White Teeth   \n",
       "46                                     Book Thief,The   \n",
       "47                                          Ghost,The   \n",
       "48              Hunger Games,The:Hunger Games Trilogy   \n",
       "49  Jamie's Ministry of Food:Anyone Can Learn to C...   \n",
       "\n",
       "                Author Name Volume sold                       Publisher  \\\n",
       "0             Rowling, J.K.   4,475,152                      Bloomsbury   \n",
       "1             Rowling, J.K.   4,179,479                      Bloomsbury   \n",
       "2             Rowling, J.K.   3,583,215                      Bloomsbury   \n",
       "3             Rowling, J.K.   3,377,906                      Bloomsbury   \n",
       "4             Rowling, J.K.   2,950,264                      Bloomsbury   \n",
       "5          Meyer, Stephenie   2,315,405              Little, Brown Book   \n",
       "6              James, E. L.   2,193,928                    Random House   \n",
       "7          Meyer, Stephenie   2,152,737              Little, Brown Book   \n",
       "8          Meyer, Stephenie   2,052,876              Little, Brown Book   \n",
       "9              Haddon, Mark   1,979,552                    Random House   \n",
       "10             Bryson, Bill   1,852,919                      Transworld   \n",
       "11         Meyer, Stephenie   1,787,118              Little, Brown Book   \n",
       "12         Donaldson, Julia   1,781,269                   Pan Macmillan   \n",
       "13         Hosseini, Khaled   1,629,119                      Bloomsbury   \n",
       "14         Hosseini, Khaled   1,583,992                      Bloomsbury   \n",
       "15      Niffenegger, Audrey   1,546,886                    Random House   \n",
       "16          Fielding, Helen   1,508,205                   Pan Macmillan   \n",
       "17      Bernieres, Louis de   1,352,318                    Random House   \n",
       "18             Martel, Yann   1,310,176                       Canongate   \n",
       "19             Pelzer, Dave   1,217,712                           Orion   \n",
       "20           McCourt, Frank   1,204,058                   HarperCollins   \n",
       "21          Pullman, Philip   1,181,503                 Scholastic Ltd.   \n",
       "22            Rowling, J.K.   1,153,181                      Bloomsbury   \n",
       "23            Parsons, Tony   1,130,802                   HarperCollins   \n",
       "24  McCall Smith, Alexander   1,115,549              Little, Brown Book   \n",
       "25           Ahern, Cecelia   1,107,379                   HarperCollins   \n",
       "26       Zafon, Carlos Ruiz   1,092,349                           Orion   \n",
       "27            Grisham, John   1,087,262                    Random House   \n",
       "28          Pullman, Philip   1,037,160                 Scholastic Ltd.   \n",
       "29             Smith, Delia   1,015,956                    Random House   \n",
       "30              Boyne, John   1,004,414  Random House Childrens Books G   \n",
       "31          Pullman, Philip   1,002,314                 Scholastic Ltd.   \n",
       "32               Gray, John     992,846                   HarperCollins   \n",
       "33          Lewycka, Marina     986,115                         Penguin   \n",
       "34        Tolkien, J. R. R.     967,466                   HarperCollins   \n",
       "35           Rubenfeld, Jed     962,515                        Headline   \n",
       "36            Coelho, Paulo     956,114                   HarperCollins   \n",
       "37             Bryson, Bill     931,312                      Transworld   \n",
       "38          Fielding, Helen     924,695                   Pan Macmillan   \n",
       "39            McKenna, Paul     905,086                      Transworld   \n",
       "40            Grisham, John     869,671                    Random House   \n",
       "41          Lawson, Nigella     862,602                    Random House   \n",
       "42             Edwards, Kim     845,858                         Penguin   \n",
       "43             Hornby, Nick     828,215                         Penguin   \n",
       "44         Dawkins, Richard     816,907                      Transworld   \n",
       "45             Smith, Zadie     815,586                         Penguin   \n",
       "46            Zusak, Markus     809,641                      Transworld   \n",
       "47           Harris, Robert     807,311                    Random House   \n",
       "48         Collins, Suzanne     792,187                 Scholastic Ltd.   \n",
       "49            Oliver, Jamie     791,095                         Penguin   \n",
       "\n",
       "                                        Genre  \n",
       "0                          Children's Fiction  \n",
       "1                          Children's Fiction  \n",
       "2                          Children's Fiction  \n",
       "3                          Children's Fiction  \n",
       "4                          Children's Fiction  \n",
       "5                         Young Adult Fiction  \n",
       "6                             Romance & Sagas  \n",
       "7                         Young Adult Fiction  \n",
       "8                         Young Adult Fiction  \n",
       "9                  General & Literary Fiction  \n",
       "10                            Popular Science  \n",
       "11                        Young Adult Fiction  \n",
       "12                              Picture Books  \n",
       "13                 General & Literary Fiction  \n",
       "14                 General & Literary Fiction  \n",
       "15                 General & Literary Fiction  \n",
       "16                 General & Literary Fiction  \n",
       "17                 General & Literary Fiction  \n",
       "18                 General & Literary Fiction  \n",
       "19                     Autobiography: General  \n",
       "20                     Autobiography: General  \n",
       "21                        Young Adult Fiction  \n",
       "22                  Science Fiction & Fantasy  \n",
       "23                 General & Literary Fiction  \n",
       "24                Crime, Thriller & Adventure  \n",
       "25                 General & Literary Fiction  \n",
       "26                 General & Literary Fiction  \n",
       "27                Crime, Thriller & Adventure  \n",
       "28                        Young Adult Fiction  \n",
       "29                      Food & Drink: General  \n",
       "30                        Young Adult Fiction  \n",
       "31                        Young Adult Fiction  \n",
       "32  Popular Culture & Media: General Interest  \n",
       "33                 General & Literary Fiction  \n",
       "34                  Science Fiction & Fantasy  \n",
       "35                Crime, Thriller & Adventure  \n",
       "36                 General & Literary Fiction  \n",
       "37                             Travel Writing  \n",
       "38                 General & Literary Fiction  \n",
       "39                             Fitness & Diet  \n",
       "40                Crime, Thriller & Adventure  \n",
       "41                      Food & Drink: General  \n",
       "42                 General & Literary Fiction  \n",
       "43                 General & Literary Fiction  \n",
       "44                            Popular Science  \n",
       "45                 General & Literary Fiction  \n",
       "46                 General & Literary Fiction  \n",
       "47                 General & Literary Fiction  \n",
       "48                        Young Adult Fiction  \n",
       "49                      Food & Drink: General  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df['Book Name']=b_name\n",
    "df['Author Name']=author\n",
    "df['Volume sold']=sold\n",
    "df['Publisher']=publisher\n",
    "df['Genre']=genre\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "1. Name\n",
    "2. Year span\n",
    "3. Genre\n",
    "4. Run time\n",
    "5. Ratings\n",
    "6. Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "code=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    name.append(text)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010– )',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014– )',\n",
       " '(2012–2020)',\n",
       " '(2017– )',\n",
       " '(2007–2019)',\n",
       " '(2011– )',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016– )',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016– )',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2021)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013– )',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016– )',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2022)',\n",
       " '(2013–2015)',\n",
       " '(2019– )',\n",
       " '(2014– )',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2021)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017– )',\n",
       " '(2016– )',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005–2020)',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year=[]\n",
    "code=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    year.append(text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Mystery',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Fantasy',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Horror',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre=[]\n",
    "code=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    genre.append(text)\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time=[]\n",
    "code=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    time.append(text)\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '6.9',\n",
       " '7.6',\n",
       " '7.7',\n",
       " '7.5',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.6',\n",
       " '8.6',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.2',\n",
       " '6.3',\n",
       " '7.4',\n",
       " '8.3',\n",
       " '7.8',\n",
       " '8.6',\n",
       " '7.9',\n",
       " '8.4',\n",
       " '9.2',\n",
       " '6.6',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.8',\n",
       " '7.6',\n",
       " '8.3',\n",
       " '8.6',\n",
       " '7.7',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.6',\n",
       " '6.9',\n",
       " '8.1',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.4',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '6.7',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.6',\n",
       " '8',\n",
       " '9',\n",
       " '7.9',\n",
       " '7.5',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.5',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.3',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.2',\n",
       " '8.6']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "code=driver.find_elements_by_xpath(\"//span[@class='ipl-rating-star__rating']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    rating.append(text)\n",
    "Rating=[]\n",
    "Rating=rating[0:-1:23]\n",
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TV-MA',\n",
       " '|',\n",
       " '57 min',\n",
       " '|',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Votes:',\n",
       " '1,779,004',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '51 min',\n",
       " '|',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Votes:',\n",
       " '829,500',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Votes:',\n",
       " '857,112',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Votes:',\n",
       " '257,306',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '43 min',\n",
       " '|',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Votes:',\n",
       " '217,861',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '59 min',\n",
       " '|',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Votes:',\n",
       " '279,529',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '119,859',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '41 min',\n",
       " '|',\n",
       " 'Drama, Romance',\n",
       " 'Votes:',\n",
       " '252,627',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '43 min',\n",
       " '|',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Votes:',\n",
       " '306,448',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Votes:',\n",
       " '408,415',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '70 min',\n",
       " '|',\n",
       " 'Action, Crime, Mystery',\n",
       " 'Votes:',\n",
       " '302,990',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Comedy, Romance',\n",
       " 'Votes:',\n",
       " '725,553',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Votes:',\n",
       " '447,795',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '88 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '811,123',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Votes:',\n",
       " '436,138',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Votes:',\n",
       " '152,734',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '43 min',\n",
       " '|',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Votes:',\n",
       " '284,415',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Votes:',\n",
       " '278,387',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '49 min',\n",
       " '|',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Votes:',\n",
       " '1,475,118',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Votes:',\n",
       " '234,976',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Votes:',\n",
       " '393,957',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Action, Crime, Drama',\n",
       " 'Votes:',\n",
       " '478,368',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '43 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '130,380',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '41 min',\n",
       " '|',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Votes:',\n",
       " '127,508',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Animation, Comedy',\n",
       " 'Votes:',\n",
       " '367,007',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Votes:',\n",
       " '209,045',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '49 min',\n",
       " '|',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Votes:',\n",
       " '359,988',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '54 min',\n",
       " '|',\n",
       " 'Action, Crime, Drama',\n",
       " 'Votes:',\n",
       " '363,894',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Comedy, Romance',\n",
       " 'Votes:',\n",
       " '833,024',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Comedy, Romance',\n",
       " 'Votes:',\n",
       " '605,454',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Comedy, Drama',\n",
       " 'Votes:',\n",
       " '364,954',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '49 min',\n",
       " '|',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Votes:',\n",
       " '335,116',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Votes:',\n",
       " '118,178',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '43 min',\n",
       " '|',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Votes:',\n",
       " '111,669',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Drama, Romance',\n",
       " 'Votes:',\n",
       " '154,942',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Votes:',\n",
       " '140,031',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Action, Crime, Drama',\n",
       " 'Votes:',\n",
       " '212,386',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '62 min',\n",
       " '|',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Votes:',\n",
       " '430,271',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '56 min',\n",
       " '|',\n",
       " 'Action, Crime, Drama',\n",
       " 'Votes:',\n",
       " '193,720',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Votes:',\n",
       " '358,313',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '23 min',\n",
       " '|',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Votes:',\n",
       " '378,667',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Votes:',\n",
       " '53,718',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '25 min',\n",
       " '|',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Votes:',\n",
       " '147,450',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '51 min',\n",
       " '|',\n",
       " 'Drama',\n",
       " 'Votes:',\n",
       " '468,156',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '287,667',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Votes:',\n",
       " '49,133',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Comedy, Drama',\n",
       " 'Votes:',\n",
       " '160,357',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '46 min',\n",
       " '|',\n",
       " 'Comedy, Drama',\n",
       " 'Votes:',\n",
       " '204,532',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Comedy',\n",
       " 'Votes:',\n",
       " '193,441',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Votes:',\n",
       " '200,543',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Votes:',\n",
       " '145,301',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '53 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '648,395',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Votes:',\n",
       " '112,880',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Animation, Comedy',\n",
       " 'Votes:',\n",
       " '305,716',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '43 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '199,015',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Votes:',\n",
       " '497,559',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Crime, Drama',\n",
       " 'Votes:',\n",
       " '354,110',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Drama, Mystery',\n",
       " 'Votes:',\n",
       " '416,207',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '57,298',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Action, Drama, Sci-Fi',\n",
       " 'Votes:',\n",
       " '101,761',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '55 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '314,596',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Action, Crime, Drama',\n",
       " 'Votes:',\n",
       " '66,812',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Votes:',\n",
       " '92,337',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Votes:',\n",
       " '173,733',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Votes:',\n",
       " '78,350',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '41 min',\n",
       " '|',\n",
       " 'Drama',\n",
       " 'Votes:',\n",
       " '63,647',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Comedy',\n",
       " 'Votes:',\n",
       " '39,062',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Votes:',\n",
       " '137,089',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Animation, Comedy',\n",
       " 'Votes:',\n",
       " '332,565',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Comedy, Crime',\n",
       " 'Votes:',\n",
       " '228,701',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '43 min',\n",
       " '|',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Votes:',\n",
       " '101,324',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Votes:',\n",
       " '160,999',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '55 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '501,592',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Votes:',\n",
       " '91,127',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '116,119',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '46 min',\n",
       " '|',\n",
       " 'Crime, Drama',\n",
       " 'Votes:',\n",
       " '326,640',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Votes:',\n",
       " '97,415',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '53 min',\n",
       " '|',\n",
       " 'Action, Crime, Drama',\n",
       " 'Votes:',\n",
       " '185,469',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '30 min',\n",
       " '|',\n",
       " 'Comedy, Drama',\n",
       " 'Votes:',\n",
       " '60,990',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Drama',\n",
       " 'Votes:',\n",
       " '15,011',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Votes:',\n",
       " '108,193',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '22 min',\n",
       " '|',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Votes:',\n",
       " '116,509',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '55 min',\n",
       " '|',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Votes:',\n",
       " '115,196',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Votes:',\n",
       " '31,087',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Votes:',\n",
       " '219,597',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '44 min',\n",
       " '|',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Votes:',\n",
       " '112,761',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '55 min',\n",
       " '|',\n",
       " 'Action, Crime, Drama',\n",
       " 'Votes:',\n",
       " '117,210',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '43 min',\n",
       " '|',\n",
       " 'Drama, Thriller',\n",
       " 'Votes:',\n",
       " '67,437',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '50 min',\n",
       " '|',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Votes:',\n",
       " '91,259',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '60 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '158,124',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Votes:',\n",
       " '22,745',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '43 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '166,062',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '58 min',\n",
       " '|',\n",
       " 'Biography, Drama, History',\n",
       " 'Votes:',\n",
       " '152,889',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '330 min',\n",
       " '|',\n",
       " 'Drama, History, Thriller',\n",
       " 'Votes:',\n",
       " '548,411',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Votes:',\n",
       " '60,655',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Drama, Fantasy',\n",
       " 'Votes:',\n",
       " '43,783',\n",
       " 'TV-PG',\n",
       " '|',\n",
       " '50 min',\n",
       " '|',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Votes:',\n",
       " '54,119',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '42 min',\n",
       " '|',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Votes:',\n",
       " '162,353',\n",
       " 'TV-14',\n",
       " '|',\n",
       " '45 min',\n",
       " '|',\n",
       " 'Crime, Drama, Horror',\n",
       " 'Votes:',\n",
       " '34,212',\n",
       " 'TV-MA',\n",
       " '|',\n",
       " '572 min',\n",
       " '|',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Votes:',\n",
       " '184,035']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes=[]\n",
    "code=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    votes.append(text)\n",
    "Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,779,004',\n",
       " '829,500',\n",
       " '857,112',\n",
       " '257,306',\n",
       " '217,861',\n",
       " '279,529',\n",
       " '119,859',\n",
       " '252,627',\n",
       " '306,448',\n",
       " '408,415',\n",
       " '302,990',\n",
       " '725,553',\n",
       " '447,795',\n",
       " '811,123',\n",
       " '436,138',\n",
       " '152,734',\n",
       " '284,415',\n",
       " '278,387',\n",
       " '1,475,118',\n",
       " '234,976',\n",
       " '393,957',\n",
       " '478,368',\n",
       " '130,380',\n",
       " '127,508',\n",
       " '367,007',\n",
       " '209,045',\n",
       " '359,988',\n",
       " '363,894',\n",
       " '833,024',\n",
       " '605,454',\n",
       " '364,954',\n",
       " '335,116',\n",
       " '118,178',\n",
       " '111,669',\n",
       " '154,942',\n",
       " '140,031',\n",
       " '212,386',\n",
       " '430,271',\n",
       " '193,720',\n",
       " '358,313',\n",
       " '378,667',\n",
       " '53,718',\n",
       " '147,450',\n",
       " '468,156',\n",
       " '287,667',\n",
       " '49,133',\n",
       " '160,357',\n",
       " '204,532',\n",
       " '193,441',\n",
       " '200,543',\n",
       " '145,301',\n",
       " '648,395',\n",
       " '112,880',\n",
       " '305,716',\n",
       " '199,015',\n",
       " '497,559',\n",
       " '354,110',\n",
       " '416,207',\n",
       " '57,298',\n",
       " '101,761',\n",
       " '314,596',\n",
       " '66,812',\n",
       " '92,337',\n",
       " '173,733',\n",
       " '78,350',\n",
       " '63,647',\n",
       " '39,062',\n",
       " '137,089',\n",
       " '332,565',\n",
       " '228,701',\n",
       " '101,324',\n",
       " '160,999',\n",
       " '501,592',\n",
       " '91,127',\n",
       " '116,119',\n",
       " '326,640',\n",
       " '97,415',\n",
       " '185,469',\n",
       " '60,990',\n",
       " '15,011',\n",
       " '108,193',\n",
       " '116,509',\n",
       " '115,196',\n",
       " '31,087',\n",
       " '219,597',\n",
       " '112,761',\n",
       " '117,210',\n",
       " '67,437',\n",
       " '91,259',\n",
       " '158,124',\n",
       " '22,745',\n",
       " '166,062',\n",
       " '152,889',\n",
       " '548,411',\n",
       " '60,655',\n",
       " '43,783',\n",
       " '54,119',\n",
       " '162,353',\n",
       " '34,212',\n",
       " '184,035']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Votes=[]\n",
    "Votes=votes[6:701:7]\n",
    "Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,779,004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>829,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010– )</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>857,112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>257,306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>217,861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>43,783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>54,119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>162,353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Crime, Drama, Horror</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.2</td>\n",
       "      <td>34,212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>184,035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name         Year                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead     (2010– )   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Crime, Drama, Horror   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "    Runtime Rating      Votes  \n",
       "0    57 min    9.3  1,779,004  \n",
       "1    51 min    8.7    829,500  \n",
       "2    44 min    8.2    857,112  \n",
       "3    60 min    7.6    257,306  \n",
       "4    43 min    7.6    217,861  \n",
       "..      ...    ...        ...  \n",
       "95   42 min    7.5     43,783  \n",
       "96   50 min    7.8     54,119  \n",
       "97   42 min    8.1    162,353  \n",
       "98   45 min    7.2     34,212  \n",
       "99  572 min    8.6    184,035  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Dataframe\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Name']=name\n",
    "df['Year']=year\n",
    "df['Genre']=genre\n",
    "df['Runtime']=time\n",
    "df['Rating']=Rating\n",
    "df['Votes']=Votes\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "1. Dataset name\n",
    "2. Data type\n",
    "3. Task\n",
    "4. Attribute type\n",
    "5. No of instances\n",
    "6. No of attribute\n",
    "7. Year\n",
    "\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://archive.ics.uci.edu/ml/datasets.php')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone',\n",
       " 'Adult',\n",
       " 'Annealing',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " 'Arrhythmia',\n",
       " 'Artificial Characters',\n",
       " 'Audiology (Original)',\n",
       " 'Audiology (Standardized)',\n",
       " 'Auto MPG',\n",
       " 'Automobile',\n",
       " 'Badges',\n",
       " 'Balance Scale',\n",
       " 'Balloons',\n",
       " 'Breast Cancer',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Car Evaluation',\n",
       " 'Census Income',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Bach Chorales',\n",
       " 'Connect-4',\n",
       " 'Credit Approval',\n",
       " 'Japanese Credit Screening',\n",
       " 'Computer Hardware',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Covertype',\n",
       " 'Cylinder Bands',\n",
       " 'Dermatology',\n",
       " 'Diabetes',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Document Understanding',\n",
       " 'EBL Domain Theories',\n",
       " 'Echocardiogram',\n",
       " 'Ecoli',\n",
       " 'Flags',\n",
       " 'Function Finding',\n",
       " 'Glass Identification',\n",
       " \"Haberman's Survival\",\n",
       " 'Hayes-Roth',\n",
       " 'Heart Disease',\n",
       " 'Hepatitis',\n",
       " 'Horse Colic',\n",
       " 'ICU',\n",
       " 'Image Segmentation',\n",
       " 'Internet Advertisements',\n",
       " 'Ionosphere',\n",
       " 'Iris',\n",
       " 'ISOLET',\n",
       " 'Kinship',\n",
       " 'Labor Relations',\n",
       " 'LED Display Domain',\n",
       " 'Lenses',\n",
       " 'Letter Recognition',\n",
       " 'Liver Disorders',\n",
       " 'Logic Theorist',\n",
       " 'Lung Cancer',\n",
       " 'Lymphography',\n",
       " 'Mechanical Analysis',\n",
       " 'Meta-data',\n",
       " 'Mobile Robots',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " \"MONK's Problems\",\n",
       " 'Moral Reasoner',\n",
       " 'Multiple Features',\n",
       " 'Mushroom',\n",
       " 'Musk (Version 1)',\n",
       " 'Musk (Version 2)',\n",
       " 'Nursery',\n",
       " 'Othello Domain Theory',\n",
       " 'Page Blocks Classification',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Post-Operative Patient',\n",
       " 'Primary Tumor',\n",
       " 'Prodigy',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Quadruped Mammals',\n",
       " 'Servo',\n",
       " 'Shuttle Landing Control',\n",
       " 'Solar Flare',\n",
       " 'Soybean (Large)',\n",
       " 'Soybean (Small)',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Spambase',\n",
       " 'SPECT Heart',\n",
       " 'SPECTF Heart',\n",
       " 'Sponge',\n",
       " 'Statlog Project',\n",
       " 'Student Loan Relational',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Thyroid Disease',\n",
       " 'Trains',\n",
       " 'University',\n",
       " 'Congressional Voting Records',\n",
       " 'Water Treatment Plant',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Wine',\n",
       " 'Yeast',\n",
       " 'Zoo',\n",
       " 'Undocumented',\n",
       " 'Twenty Newsgroups',\n",
       " 'Australian Sign Language signs',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'US Census Data (1990)',\n",
       " 'Census-Income (KDD)',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Corel Image Features',\n",
       " 'E. Coli Genes',\n",
       " 'EEG Database',\n",
       " 'El Nino',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'CMU Face Images',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Internet Usage Data',\n",
       " 'IPUMS Census Database',\n",
       " 'Japanese Vowels',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Movie',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Robot Execution Failures',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'UNIX User Data',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Statlog (Heart)',\n",
       " 'Statlog (Landsat Satellite)',\n",
       " 'Statlog (Image Segmentation)',\n",
       " 'Statlog (Shuttle)',\n",
       " 'Statlog (Vehicle Silhouettes)',\n",
       " 'Connectionist Bench (Nettalk Corpus)',\n",
       " 'Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " 'Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " 'Economic Sanctions',\n",
       " 'Protein Data',\n",
       " 'Cloud',\n",
       " 'CalIt2 Building People Counts',\n",
       " 'Dodgers Loop Sensor',\n",
       " 'Poker Hand',\n",
       " 'MAGIC Gamma Telescope',\n",
       " 'UJI Pen Characters',\n",
       " 'Mammographic Mass',\n",
       " 'Forest Fires',\n",
       " 'Reuters Transcribed Subset',\n",
       " 'Bag of Words',\n",
       " 'Concrete Compressive Strength',\n",
       " 'Hill-Valley',\n",
       " 'Arcene',\n",
       " 'Dexter',\n",
       " 'Dorothea',\n",
       " 'Gisette',\n",
       " 'Madelon',\n",
       " 'Ozone Level Detection',\n",
       " 'Abscisic Acid Signaling Network',\n",
       " 'Parkinsons',\n",
       " 'Character Trajectories',\n",
       " 'Blood Transfusion Service Center',\n",
       " 'UJI Pen Characters (Version 2)',\n",
       " 'Semeion Handwritten Digit',\n",
       " 'SECOM',\n",
       " 'Plants',\n",
       " 'Libras Movement',\n",
       " 'Concrete Slump Test',\n",
       " 'Communities and Crime',\n",
       " 'Acute Inflammations',\n",
       " 'Wine Quality',\n",
       " 'URL Reputation',\n",
       " 'p53 Mutants',\n",
       " 'Parkinsons Telemonitoring',\n",
       " 'Demospongiae',\n",
       " 'Opinosis Opinion ⁄ Review',\n",
       " 'Breast Tissue',\n",
       " 'Cardiotocography',\n",
       " 'Wall-Following Robot Navigation Data',\n",
       " 'Spoken Arabic Digit',\n",
       " 'Localization Data for Person Activity',\n",
       " 'AutoUniv',\n",
       " 'Steel Plates Faults',\n",
       " 'MiniBooNE particle identification',\n",
       " 'YearPredictionMSD',\n",
       " 'PEMS-SF',\n",
       " 'OpinRank Review Dataset',\n",
       " 'Relative location of CT slices on axial axis',\n",
       " 'Online Handwritten Assamese Characters Dataset',\n",
       " 'PubChem Bioassay Data',\n",
       " 'Record Linkage Comparison Patterns',\n",
       " 'Communities and Crime Unnormalized',\n",
       " 'Vertebral Column',\n",
       " 'EMG Physical Action Data Set',\n",
       " 'Vicon Physical Action Data Set',\n",
       " 'Amazon Commerce reviews set',\n",
       " 'Amazon Access Samples',\n",
       " 'Reuter_50_50',\n",
       " 'Farm Ads',\n",
       " 'DBWorld e-mails',\n",
       " 'KEGG Metabolic Relation Network (Directed)',\n",
       " 'KEGG Metabolic Reaction Network (Undirected)',\n",
       " 'Bank Marketing',\n",
       " 'YouTube Comedy Slam Preference Data',\n",
       " 'Gas Sensor Array Drift Dataset',\n",
       " 'ILPD (Indian Liver Patient Dataset)',\n",
       " 'OPPORTUNITY Activity Recognition',\n",
       " 'Nomao',\n",
       " 'SMS Spam Collection',\n",
       " 'Skin Segmentation',\n",
       " 'Planning Relax',\n",
       " 'PAMAP2 Physical Activity Monitoring',\n",
       " 'Restaurant & consumer data',\n",
       " 'CNAE-9',\n",
       " 'Individual household electric power consumption',\n",
       " 'seeds',\n",
       " 'Northix',\n",
       " 'QtyT40I10D100K',\n",
       " 'Legal Case Reports',\n",
       " 'Human Activity Recognition Using Smartphones',\n",
       " 'One-hundred plant species leaves data set',\n",
       " 'Energy efficiency',\n",
       " 'Yacht Hydrodynamics',\n",
       " 'Fertility',\n",
       " 'Daphnet Freezing of Gait',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'ISTANBUL STOCK EXCHANGE',\n",
       " 'Buzz in social media',\n",
       " 'First-order theorem proving',\n",
       " 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " 'Gas sensor arrays in open sampling settings',\n",
       " 'Climate Model Simulation Crashes',\n",
       " 'MicroMass',\n",
       " 'QSAR biodegradation',\n",
       " 'BLOGGER',\n",
       " 'Daily and Sports Activities',\n",
       " 'User Knowledge Modeling',\n",
       " 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " 'NYSK',\n",
       " 'Turkiye Student Evaluation',\n",
       " \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " 'EEG Eye State',\n",
       " 'Physicochemical Properties of Protein Tertiary Structure',\n",
       " 'seismic-bumps',\n",
       " 'banknote authentication',\n",
       " 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " 'YouTube Multiview Video Games Dataset',\n",
       " 'Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " 'SkillCraft1 Master Table Dataset',\n",
       " 'Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " 'SML2010',\n",
       " 'Bike Sharing Dataset',\n",
       " 'Predict keywords activities in a online social media',\n",
       " 'Thoracic Surgery Data',\n",
       " 'EMG dataset in Lower Limb',\n",
       " 'SUSY',\n",
       " 'HIGGS',\n",
       " 'Qualitative_Bankruptcy',\n",
       " 'LSVT Voice Rehabilitation',\n",
       " 'Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " 'Wilt',\n",
       " 'User Identification From Walking Activity',\n",
       " 'Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " 'Leaf',\n",
       " 'Dresses_Attribute_Sales',\n",
       " 'Tamilnadu Electricity Board Hourly Readings',\n",
       " 'Airfoil Self-Noise',\n",
       " 'Wholesale customers',\n",
       " 'Twitter Data set for Arabic Sentiment Analysis',\n",
       " 'Combined Cycle Power Plant',\n",
       " 'Urban Land Cover',\n",
       " 'Diabetes 130-US hospitals for years 1999-2008',\n",
       " 'Bach Choral Harmony',\n",
       " 'StoneFlakes',\n",
       " 'Tennis Major Tournament Match Statistics',\n",
       " 'Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " 'Gesture Phase Segmentation',\n",
       " 'Perfume Data',\n",
       " 'BlogFeedback',\n",
       " 'REALDISP Activity Recognition Dataset',\n",
       " 'Newspaper and magazine images segmentation dataset',\n",
       " 'AAAI 2014 Accepted Papers',\n",
       " 'Gas sensor array under flow modulation',\n",
       " 'Gas sensor array exposed to turbulent gas mixtures',\n",
       " 'UJIIndoorLoc',\n",
       " 'Sentence Classification',\n",
       " 'Dow Jones Index',\n",
       " 'sEMG for Basic Hand movements',\n",
       " 'AAAI 2013 Accepted Papers',\n",
       " 'Geographical Original of Music',\n",
       " 'Condition Based Maintenance of Naval Propulsion Plants',\n",
       " 'Grammatical Facial Expressions',\n",
       " 'NoisyOffice',\n",
       " 'MHEALTH Dataset',\n",
       " 'Student Performance',\n",
       " 'ElectricityLoadDiagrams20112014',\n",
       " 'Gas sensor array under dynamic gas mixtures',\n",
       " 'microblogPCU',\n",
       " 'Firm-Teacher_Clave-Direction_Classification',\n",
       " 'Dataset for Sensorless Drive Diagnosis',\n",
       " 'TV News Channel Commercial Detection Dataset',\n",
       " 'Phishing Websites',\n",
       " 'Greenhouse Gas Observing Network',\n",
       " 'Diabetic Retinopathy Debrecen Data Set',\n",
       " 'HIV-1 protease cleavage',\n",
       " 'Sentiment Labelled Sentences',\n",
       " 'Online News Popularity',\n",
       " 'Forest type mapping',\n",
       " 'wiki4HE',\n",
       " 'Online Video Characteristics and Transcoding Time Dataset',\n",
       " 'Chronic_Kidney_Disease',\n",
       " 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " 'Folio',\n",
       " 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " 'Cuff-Less Blood Pressure Estimation',\n",
       " 'Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " 'Mice Protein Expression',\n",
       " 'UJIIndoorLoc-Mag',\n",
       " 'Heterogeneity Activity Recognition',\n",
       " 'Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " 'HEPMASS',\n",
       " 'Indoor User Movement Prediction from RSS data',\n",
       " 'Open University Learning Analytics dataset',\n",
       " 'default of credit card clients',\n",
       " 'Mesothelioma’s disease data set',\n",
       " 'Online Retail',\n",
       " 'SIFT10M',\n",
       " 'GPS Trajectories',\n",
       " 'Detect Malacious Executable(AntiVirus)',\n",
       " 'Occupancy Detection',\n",
       " 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease',\n",
       " 'News Aggregator',\n",
       " 'Air Quality',\n",
       " 'Twin gas sensor arrays',\n",
       " 'Gas sensors for home activity monitoring',\n",
       " 'Facebook Comment Volume Dataset',\n",
       " 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " 'Polish companies bankruptcy data',\n",
       " 'Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " 'Dota2 Games Results',\n",
       " 'Facebook metrics',\n",
       " 'UbiqLog (smartphone lifelogging)',\n",
       " 'NIPS Conference Papers 1987-2015',\n",
       " 'HTRU2',\n",
       " 'Drug consumption (quantified)',\n",
       " 'Appliances energy prediction',\n",
       " 'Miskolc IIS Hybrid IPS',\n",
       " 'KDC-4007 dataset Collection',\n",
       " 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " 'DrivFace',\n",
       " 'Website Phishing',\n",
       " 'YouTube Spam Collection',\n",
       " 'Beijing PM2.5 Data',\n",
       " 'Cargo 2000 Freight Tracking and Tracing',\n",
       " 'Cervical cancer (Risk Factors)',\n",
       " 'Quality Assessment of Digital Colposcopies',\n",
       " 'KASANDR',\n",
       " 'FMA: A Dataset For Music Analysis',\n",
       " 'Air quality',\n",
       " 'Epileptic Seizure Recognition',\n",
       " 'Devanagari Handwritten Character Dataset',\n",
       " 'Stock portfolio performance',\n",
       " 'MoCap Hand Postures',\n",
       " 'Early biomarkers of Parkinson�s disease based on natural connected speech',\n",
       " 'Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " 'PM2.5 Data of Five Chinese Cities',\n",
       " 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " 'Sales_Transactions_Dataset_Weekly',\n",
       " 'Las Vegas Strip',\n",
       " 'Eco-hotel',\n",
       " 'MEU-Mobile KSD',\n",
       " 'Crowdsourced Mapping',\n",
       " 'gene expression cancer RNA-Seq',\n",
       " 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " 'chestnut – LARVIC',\n",
       " 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " 'Motion Capture Hand Postures',\n",
       " 'Anuran Calls (MFCCs)',\n",
       " 'TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " 'Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " 'Daily Demand Forecasting Orders',\n",
       " 'Paper Reviews',\n",
       " 'extention of Z-Alizadeh sani dataset',\n",
       " 'Z-Alizadeh Sani',\n",
       " 'Dynamic Features of VirusShare Executables',\n",
       " 'IDA2016Challenge',\n",
       " 'DSRC Vehicle Communications',\n",
       " 'Mturk User-Perceived Clusters over Images',\n",
       " 'Character Font Images',\n",
       " 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " 'Autistic Spectrum Disorder Screening Data for Children',\n",
       " 'Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " 'APS Failure at Scania Trucks',\n",
       " 'Wireless Indoor Localization',\n",
       " 'HCC Survival',\n",
       " 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " 'University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " 'Autism Screening Adult',\n",
       " 'Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " 'Immunotherapy Dataset',\n",
       " 'Cryotherapy Dataset',\n",
       " 'OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " 'Discrete Tone Image Dataset',\n",
       " 'News Popularity in Multiple Social Media Platforms',\n",
       " 'Ultrasonic flowmeter diagnostics',\n",
       " 'ICMLA 2014 Accepted Papers Data Set',\n",
       " 'BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " 'Container Crane Controller Data Set',\n",
       " 'Residential Building Data Set',\n",
       " 'Health News in Twitter',\n",
       " 'chipseq',\n",
       " 'SGEMM GPU kernel performance',\n",
       " 'Repeat Consumption Matrices',\n",
       " 'detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " 'Absenteeism at work',\n",
       " 'SCADI',\n",
       " 'Condition monitoring of hydraulic systems',\n",
       " 'Carbon Nanotubes',\n",
       " 'Optical Interconnection Network',\n",
       " 'Sports articles for objectivity analysis',\n",
       " 'Breast Cancer Coimbra',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " 'Dishonest Internet users Dataset',\n",
       " 'Victorian Era Authorship Attribution',\n",
       " 'Simulated Falls and Daily Living Activities Data Set',\n",
       " 'Multimodal Damage Identification for Humanitarian Computing',\n",
       " 'EEG Steady-State Visual Evoked Potential Signals',\n",
       " 'Roman Urdu Data Set',\n",
       " 'Avila',\n",
       " 'PANDOR',\n",
       " 'Drug Review Dataset (Druglib.com)',\n",
       " 'Drug Review Dataset (Drugs.com)',\n",
       " 'Physical Unclonable Functions',\n",
       " 'Superconductivty Data',\n",
       " 'WESAD (Wearable Stress and Affect Detection)',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " 'Student Academics Performance',\n",
       " 'Online Shoppers Purchasing Intention Dataset',\n",
       " 'PMU-UD',\n",
       " \"Parkinson's Disease Classification\",\n",
       " 'Electrical Grid Stability Simulated Data',\n",
       " 'Caesarian Section Classification Dataset',\n",
       " 'BAUM-1',\n",
       " 'BAUM-2',\n",
       " 'Audit Data',\n",
       " 'BuddyMove Data Set',\n",
       " 'Real estate valuation data set',\n",
       " 'Early biomarkers of Parkinson’s disease based on natural connected speech Data Set',\n",
       " 'Somerville Happiness Survey',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'EMG data for gestures',\n",
       " 'Parking Birmingham',\n",
       " 'Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " 'Travel Reviews',\n",
       " 'Tarvel Review Ratings',\n",
       " 'Rice Leaf Diseases',\n",
       " 'Gas sensor array temperature modulation',\n",
       " 'Facebook Live Sellers in Thailand',\n",
       " 'Parkinson Dataset with replicated acoustic features',\n",
       " 'Metro Interstate Traffic Volume',\n",
       " 'Query Analytics Workloads Dataset',\n",
       " 'Wave Energy Converters',\n",
       " 'PPG-DaLiA',\n",
       " 'Alcohol QCM Sensor Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " 'Incident management process enriched event log',\n",
       " 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " 'MEx',\n",
       " 'Beijing Multi-Site Air-Quality Data',\n",
       " 'Online Retail II',\n",
       " 'Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " 'QSAR fish toxicity',\n",
       " 'QSAR aquatic toxicity',\n",
       " 'Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " 'QSAR oral toxicity',\n",
       " 'QSAR androgen receptor',\n",
       " 'QSAR Bioconcentration classes dataset',\n",
       " 'QSAR fish bioconcentration factor (BCF)',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Real-time Election Results: Portugal 2019',\n",
       " 'Bias correction of numerical prediction model temperature forecast',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Kitsune Network Attack Dataset',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'Speaker Accent Recognition',\n",
       " 'Heart failure clinical records',\n",
       " 'Deepfakes: Medical Image Tamper Detection',\n",
       " 'selfBACK',\n",
       " 'South German Credit',\n",
       " 'Exasens',\n",
       " 'Swarm Behaviour',\n",
       " 'Crop mapping using fused optical-radar data set',\n",
       " 'BitcoinHeistRansomwareAddressDataset',\n",
       " 'Facebook Large Page-Page Network',\n",
       " 'Amphibians',\n",
       " 'Early stage diabetes risk prediction dataset.',\n",
       " 'Turkish Spam V01',\n",
       " 'Stock keeping units',\n",
       " 'Demand Forecasting for a store',\n",
       " 'Detect Malware Types',\n",
       " 'Wave Energy Converters',\n",
       " 'Youtube cookery channels viewers comments in Hinglish',\n",
       " 'Pedestrian in Traffic Dataset',\n",
       " 'Cervical Cancer Behavior Risk',\n",
       " 'Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " '3W dataset',\n",
       " 'Malware static and dynamic features VxHeaven and Virus Total',\n",
       " 'Internet Firewall Data',\n",
       " 'User Profiling and Abusive Language Detection Dataset',\n",
       " 'Estimation of obesity levels based on eating habits and physical condition',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Vehicle routing and scheduling problems',\n",
       " 'Algerian Forest Fires Dataset',\n",
       " 'Breath Metabolomics',\n",
       " 'Horton General Hospital',\n",
       " 'UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       " 'Gas Turbine CO and NOx Emission Data Set',\n",
       " 'Activity recognition using wearable physiological measurements',\n",
       " 'clickstream data for online shopping',\n",
       " 'CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       " 'Apartment for rent classified',\n",
       " ': Simulated Data set of Iraqi tourism places',\n",
       " 'Nasarian CAD Dataset',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Seoul Bike Sharing Demand',\n",
       " 'Person Classification Gait Data',\n",
       " 'Shill Bidding Dataset',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Bone marrow transplant: children',\n",
       " 'Exasens',\n",
       " 'COVID-19 Surveillance',\n",
       " 'Refractive errors',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'CLINC150',\n",
       " 'HCV data',\n",
       " 'Taiwanese Bankruptcy Prediction',\n",
       " 'South German Credit (UPDATE)',\n",
       " 'IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       " 'Guitar Chords finger positions',\n",
       " 'Russian Corpus of Biographical Texts',\n",
       " 'Codon usage',\n",
       " 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       " 'Myocardial infarction complications',\n",
       " 'Hungarian Chickenpox Cases',\n",
       " 'Simulated data for survival modelling',\n",
       " 'Student Performance on an entrance examination',\n",
       " 'Chemical Composition of Ceramic Samples',\n",
       " 'Labeled Text Forum Threads Dataset',\n",
       " 'Stock keeping units',\n",
       " 'BLE RSSI dataset for Indoor localization',\n",
       " 'Basketball dataset',\n",
       " 'GitHub MUSAE',\n",
       " 'Anticancer peptides',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Gender by Name',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wheat kernels',\n",
       " 'Productivity Prediction of Garment Employees',\n",
       " 'Multi-view Brain Networks',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wisesight Sentiment Corpus',\n",
       " 'AI4I 2020 Predictive Maintenance Dataset',\n",
       " 'Dry Bean Dataset',\n",
       " 'in-vehicle coupon recommendation',\n",
       " 'Gait Classification']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_name=[]\n",
    "code=driver.find_elements_by_xpath(\"//b/a\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    d_name.append(text)\n",
    "d_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification (442)\\nRegression (134)\\nClustering (117)\\nOther (56)',\n",
       " 'Categorical (38)\\nNumerical (393)\\nMixed (55)',\n",
       " 'Multivariate (455)\\nUnivariate (27)\\nSequential (57)\\nTime-Series (119)\\nText (66)\\nDomain-Theory (23)\\nOther (21)',\n",
       " 'Life Sciences (138)\\nPhysical Sciences (57)\\nCS / Engineering (214)\\nSocial Sciences (36)\\nBusiness (44)\\nGame (11)\\nOther (80)',\n",
       " 'Less than 10 (150)\\n10 to 100 (266)\\nGreater than 100 (104)',\n",
       " 'Less than 100 (36)\\n100 to 1000 (196)\\nGreater than 1000 (318)',\n",
       " 'Matrix (408)\\nNon-Matrix (177)',\n",
       " 'Table View  List View',\n",
       " 'Abalone',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '4177 ',\n",
       " '8 ',\n",
       " '1995 ',\n",
       " 'Adult',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '48842 ',\n",
       " '14 ',\n",
       " '1996 ',\n",
       " 'Annealing',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '798 ',\n",
       " '38 ',\n",
       " ' ',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " ' ',\n",
       " 'Recommender-Systems ',\n",
       " 'Categorical ',\n",
       " '37711 ',\n",
       " '294 ',\n",
       " '1998 ',\n",
       " 'Arrhythmia',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '452 ',\n",
       " '279 ',\n",
       " '1998 ',\n",
       " 'Artificial Characters',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '6000 ',\n",
       " '7 ',\n",
       " '1992 ',\n",
       " 'Audiology (Original)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '226 ',\n",
       " ' ',\n",
       " '1987 ',\n",
       " 'Audiology (Standardized)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '226 ',\n",
       " '69 ',\n",
       " '1992 ',\n",
       " 'Auto MPG',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical, Real ',\n",
       " '398 ',\n",
       " '8 ',\n",
       " '1993 ',\n",
       " 'Automobile',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '205 ',\n",
       " '26 ',\n",
       " '1987 ',\n",
       " 'Badges',\n",
       " 'Univariate, Text ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " '294 ',\n",
       " '1 ',\n",
       " '1994 ',\n",
       " 'Balance Scale',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '625 ',\n",
       " '4 ',\n",
       " '1994 ',\n",
       " 'Balloons',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '16 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " 'Breast Cancer',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '286 ',\n",
       " '9 ',\n",
       " '1988 ',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '699 ',\n",
       " '10 ',\n",
       " '1992 ',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Multivariate ',\n",
       " 'Classification, Regression ',\n",
       " 'Real ',\n",
       " '198 ',\n",
       " '34 ',\n",
       " '1995 ',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '569 ',\n",
       " '32 ',\n",
       " '1995 ',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '108 ',\n",
       " '13 ',\n",
       " '1990 ',\n",
       " 'Car Evaluation',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '1728 ',\n",
       " '6 ',\n",
       " '1997 ',\n",
       " 'Census Income',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '48842 ',\n",
       " '14 ',\n",
       " '1996 ',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " '22 ',\n",
       " '1988 ',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '3196 ',\n",
       " '36 ',\n",
       " '1989 ',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '28056 ',\n",
       " '6 ',\n",
       " '1994 ',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Bach Chorales',\n",
       " 'Univariate, Time-Series ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " '100 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " 'Connect-4',\n",
       " 'Multivariate, Spatial ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '67557 ',\n",
       " '42 ',\n",
       " '1995 ',\n",
       " 'Credit Approval',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '690 ',\n",
       " '15 ',\n",
       " ' ',\n",
       " 'Japanese Credit Screening',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Classification ',\n",
       " 'Categorical, Real, Integer ',\n",
       " '125 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " 'Computer Hardware',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Integer ',\n",
       " '209 ',\n",
       " '9 ',\n",
       " '1987 ',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '1473 ',\n",
       " '9 ',\n",
       " '1997 ',\n",
       " 'Covertype',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '581012 ',\n",
       " '54 ',\n",
       " '1998 ',\n",
       " 'Cylinder Bands',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '512 ',\n",
       " '39 ',\n",
       " '1995 ',\n",
       " 'Dermatology',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '366 ',\n",
       " '33 ',\n",
       " '1998 ',\n",
       " 'Diabetes',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " '20 ',\n",
       " ' ',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Data-Generator ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Document Understanding',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " 'EBL Domain Theories',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Echocardiogram',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '132 ',\n",
       " '12 ',\n",
       " '1989 ',\n",
       " 'Ecoli',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '336 ',\n",
       " '8 ',\n",
       " '1996 ',\n",
       " 'Flags',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '194 ',\n",
       " '30 ',\n",
       " '1990 ',\n",
       " 'Function Finding',\n",
       " ' ',\n",
       " 'Function-Learning ',\n",
       " 'Real ',\n",
       " '352 ',\n",
       " ' ',\n",
       " '1990 ',\n",
       " 'Glass Identification',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '214 ',\n",
       " '10 ',\n",
       " '1987 ',\n",
       " \"Haberman's Survival\",\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '306 ',\n",
       " '3 ',\n",
       " '1999 ',\n",
       " 'Hayes-Roth',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '160 ',\n",
       " '5 ',\n",
       " '1989 ',\n",
       " 'Heart Disease',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '303 ',\n",
       " '75 ',\n",
       " '1988 ',\n",
       " 'Hepatitis',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '155 ',\n",
       " '19 ',\n",
       " '1988 ',\n",
       " 'Horse Colic',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '368 ',\n",
       " '27 ',\n",
       " '1989 ',\n",
       " 'ICU',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Image Segmentation',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '2310 ',\n",
       " '19 ',\n",
       " '1990 ',\n",
       " 'Internet Advertisements',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '3279 ',\n",
       " '1558 ',\n",
       " '1998 ',\n",
       " 'Ionosphere',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '351 ',\n",
       " '34 ',\n",
       " '1989 ',\n",
       " 'Iris',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '150 ',\n",
       " '4 ',\n",
       " '1988 ',\n",
       " 'ISOLET',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '7797 ',\n",
       " '617 ',\n",
       " '1994 ',\n",
       " 'Kinship',\n",
       " 'Relational ',\n",
       " 'Relational-Learning ',\n",
       " 'Categorical ',\n",
       " '104 ',\n",
       " '12 ',\n",
       " '1990 ',\n",
       " 'Labor Relations',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '57 ',\n",
       " '16 ',\n",
       " '1988 ',\n",
       " 'LED Display Domain',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '1988 ',\n",
       " 'Lenses',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '24 ',\n",
       " '4 ',\n",
       " '1990 ',\n",
       " 'Letter Recognition',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '20000 ',\n",
       " '16 ',\n",
       " '1991 ',\n",
       " 'Liver Disorders',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '345 ',\n",
       " '7 ',\n",
       " '1990 ',\n",
       " 'Logic Theorist',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Lung Cancer',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '32 ',\n",
       " '56 ',\n",
       " '1992 ',\n",
       " 'Lymphography',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '148 ',\n",
       " '18 ',\n",
       " '1988 ',\n",
       " 'Mechanical Analysis',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '209 ',\n",
       " '8 ',\n",
       " '1990 ',\n",
       " 'Meta-data',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '528 ',\n",
       " '22 ',\n",
       " '1996 ',\n",
       " 'Mobile Robots',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1995 ',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '106 ',\n",
       " '58 ',\n",
       " '1990 ',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Sequential ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '128 ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '3190 ',\n",
       " '61 ',\n",
       " '1992 ',\n",
       " \"MONK's Problems\",\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '432 ',\n",
       " '7 ',\n",
       " '1992 ',\n",
       " 'Moral Reasoner',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " '202 ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " 'Multiple Features',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '2000 ',\n",
       " '649 ',\n",
       " ' ',\n",
       " 'Mushroom',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '8124 ',\n",
       " '22 ',\n",
       " '1987 ',\n",
       " 'Musk (Version 1)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '476 ',\n",
       " '168 ',\n",
       " '1994 ',\n",
       " 'Musk (Version 2)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '6598 ',\n",
       " '168 ',\n",
       " '1994 ',\n",
       " 'Nursery',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '12960 ',\n",
       " '8 ',\n",
       " '1997 ',\n",
       " 'Othello Domain Theory',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1991 ',\n",
       " 'Page Blocks Classification',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '5473 ',\n",
       " '10 ',\n",
       " '1995 ',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '5620 ',\n",
       " '64 ',\n",
       " '1998 ',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '10992 ',\n",
       " '16 ',\n",
       " '1998 ',\n",
       " 'Post-Operative Patient',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '90 ',\n",
       " '8 ',\n",
       " '1993 ',\n",
       " 'Primary Tumor',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '339 ',\n",
       " '17 ',\n",
       " '1988 ',\n",
       " 'Prodigy',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Quadruped Mammals',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " '72 ',\n",
       " '1992 ',\n",
       " 'Servo',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical, Integer ',\n",
       " '167 ',\n",
       " '4 ',\n",
       " '1993 ',\n",
       " 'Shuttle Landing Control',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '15 ',\n",
       " '6 ',\n",
       " '1988 ',\n",
       " 'Solar Flare',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical ',\n",
       " '1389 ',\n",
       " '10 ',\n",
       " '1989 ',\n",
       " 'Soybean (Large)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '307 ',\n",
       " '35 ',\n",
       " '1988 ',\n",
       " 'Soybean (Small)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '47 ',\n",
       " '35 ',\n",
       " '1987 ',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Integer ',\n",
       " '23 ',\n",
       " '4 ',\n",
       " '1993 ',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '531 ',\n",
       " '102 ',\n",
       " '1988 ',\n",
       " 'Spambase',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '4601 ',\n",
       " '57 ',\n",
       " '1999 ',\n",
       " 'SPECT Heart',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '267 ',\n",
       " '22 ',\n",
       " '2001 ',\n",
       " 'SPECTF Heart',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '267 ',\n",
       " '44 ',\n",
       " '2001 ',\n",
       " 'Sponge',\n",
       " 'Multivariate ',\n",
       " 'Clustering ',\n",
       " 'Categorical, Integer ',\n",
       " '76 ',\n",
       " '45 ',\n",
       " ' ',\n",
       " 'Statlog Project',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " 'Student Loan Relational',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1000 ',\n",
       " ' ',\n",
       " '1993 ',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '151 ',\n",
       " '5 ',\n",
       " '1997 ',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '958 ',\n",
       " '9 ',\n",
       " '1991 ',\n",
       " 'Thyroid Disease',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Classification ',\n",
       " 'Categorical, Real ',\n",
       " '7200 ',\n",
       " '21 ',\n",
       " '1987 ',\n",
       " 'Trains',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '10 ',\n",
       " '32 ',\n",
       " '1994 ',\n",
       " 'University',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '285 ',\n",
       " '17 ',\n",
       " '1988 ',\n",
       " 'Congressional Voting Records',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '435 ',\n",
       " '16 ',\n",
       " '1987 ',\n",
       " 'Water Treatment Plant',\n",
       " 'Multivariate ',\n",
       " 'Clustering ',\n",
       " 'Integer, Real ',\n",
       " '527 ',\n",
       " '38 ',\n",
       " '1993 ',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '5000 ',\n",
       " '21 ',\n",
       " '1988 ',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '5000 ',\n",
       " '40 ',\n",
       " '1988 ',\n",
       " 'Wine',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '178 ',\n",
       " '13 ',\n",
       " '1991 ',\n",
       " 'Yeast',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '1484 ',\n",
       " '8 ',\n",
       " '1996 ',\n",
       " 'Zoo',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '101 ',\n",
       " '17 ',\n",
       " '1990 ',\n",
       " 'Undocumented',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Twenty Newsgroups',\n",
       " 'Text ',\n",
       " ' ',\n",
       " ' ',\n",
       " '20000 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Australian Sign Language signs',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Classification ',\n",
       " 'Categorical, Real ',\n",
       " '6650 ',\n",
       " '15 ',\n",
       " '1999 ',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '2565 ',\n",
       " '22 ',\n",
       " '2002 ',\n",
       " 'US Census Data (1990)',\n",
       " 'Multivariate ',\n",
       " 'Clustering ',\n",
       " 'Categorical ',\n",
       " '2458285 ',\n",
       " '68 ',\n",
       " ' ',\n",
       " 'Census-Income (KDD)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '299285 ',\n",
       " '40 ',\n",
       " '2000 ',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " '340 ',\n",
       " '17 ',\n",
       " '1999 ',\n",
       " 'Corel Image Features',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " '68040 ',\n",
       " '89 ',\n",
       " '1999 ',\n",
       " 'E. Coli Genes',\n",
       " 'Relational ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '2001 ',\n",
       " 'EEG Database',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '122 ',\n",
       " '4 ',\n",
       " '1999 ',\n",
       " 'El Nino',\n",
       " 'Spatio-temporal ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " '178080 ',\n",
       " '12 ',\n",
       " '1999 ',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'Transactional, Sequential ',\n",
       " 'Recommender-Systems ',\n",
       " 'Categorical ',\n",
       " '50672 ',\n",
       " ' ',\n",
       " '2000 ',\n",
       " 'CMU Face Images',\n",
       " 'Image ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '640 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Multivariate ',\n",
       " 'Regression, Description ',\n",
       " 'Categorical, Integer ',\n",
       " '9000 ',\n",
       " '86 ',\n",
       " '2000 ',\n",
       " 'Internet Usage Data',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " '10104 ',\n",
       " '72 ',\n",
       " '1999 ',\n",
       " 'IPUMS Census Database',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " '256932 ',\n",
       " '61 ',\n",
       " '1999 ',\n",
       " 'Japanese Vowels',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '640 ',\n",
       " '12 ',\n",
       " ' ',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical, Integer ',\n",
       " '191779 ',\n",
       " '481 ',\n",
       " '1998 ',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '4000000 ',\n",
       " '42 ',\n",
       " '1999 ',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Relational ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '2001 ',\n",
       " 'Movie',\n",
       " 'Multivariate, Relational ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10000 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'Sequential ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " '989818 ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Text ',\n",
       " ' ',\n",
       " ' ',\n",
       " '129000 ',\n",
       " ' ',\n",
       " '2003 ',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Univariate, Time-Series ',\n",
       " ' ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Text ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '21578 ',\n",
       " '5 ',\n",
       " '1997 ',\n",
       " 'Robot Execution Failures',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '463 ',\n",
       " '90 ',\n",
       " '1999 ',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Time-Series ',\n",
       " 'Classification, Clustering ',\n",
       " 'Real ',\n",
       " '600 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'Multivariate, Text ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '332 ',\n",
       " '5 ',\n",
       " '1998 ',\n",
       " 'UNIX User Data',\n",
       " 'Text, Sequential ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Image ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '690 ',\n",
       " '14 ',\n",
       " ' ',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '1000 ',\n",
       " ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types=[]\n",
    "code=driver.find_elements_by_xpath(\"//td/p[@class='normal']\")\n",
    "for i in code:\n",
    "    text=i.text\n",
    "    types.append(text)\n",
    "types   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "Type=[]\n",
    "task=[]\n",
    "attri_t=[]\n",
    "inst=[]\n",
    "attri=[]\n",
    "year=[]\n",
    "name=types[8:2000:7]\n",
    "Type=types[9:2000:7]\n",
    "task=types[10:2000:7]\n",
    "attri_t=types[11:2000:7]\n",
    "inst=types[12:2000:7]\n",
    "attri=types[13:2000:7]\n",
    "year=types[14:2000:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4177 ',\n",
       " '48842 ',\n",
       " '798 ',\n",
       " '37711 ',\n",
       " '452 ',\n",
       " '6000 ',\n",
       " '226 ',\n",
       " '226 ',\n",
       " '398 ',\n",
       " '205 ',\n",
       " '294 ',\n",
       " '625 ',\n",
       " '16 ',\n",
       " '286 ',\n",
       " '699 ',\n",
       " '198 ',\n",
       " '569 ',\n",
       " '108 ',\n",
       " '1728 ',\n",
       " '48842 ',\n",
       " ' ',\n",
       " '3196 ',\n",
       " '28056 ',\n",
       " ' ',\n",
       " '100 ',\n",
       " '67557 ',\n",
       " '690 ',\n",
       " '125 ',\n",
       " '209 ',\n",
       " '1473 ',\n",
       " '581012 ',\n",
       " '512 ',\n",
       " '366 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '132 ',\n",
       " '336 ',\n",
       " '194 ',\n",
       " '352 ',\n",
       " '214 ',\n",
       " '306 ',\n",
       " '160 ',\n",
       " '303 ',\n",
       " '155 ',\n",
       " '368 ',\n",
       " ' ',\n",
       " '2310 ',\n",
       " '3279 ',\n",
       " '351 ',\n",
       " '150 ',\n",
       " '7797 ',\n",
       " '104 ',\n",
       " '57 ',\n",
       " ' ',\n",
       " '24 ',\n",
       " '20000 ',\n",
       " '345 ',\n",
       " ' ',\n",
       " '32 ',\n",
       " '148 ',\n",
       " '209 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " '106 ',\n",
       " '128 ',\n",
       " '3190 ',\n",
       " '432 ',\n",
       " '202 ',\n",
       " '2000 ',\n",
       " '8124 ',\n",
       " '476 ',\n",
       " '6598 ',\n",
       " '12960 ',\n",
       " ' ',\n",
       " '5473 ',\n",
       " '5620 ',\n",
       " '10992 ',\n",
       " '90 ',\n",
       " '339 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '167 ',\n",
       " '15 ',\n",
       " '1389 ',\n",
       " '307 ',\n",
       " '47 ',\n",
       " '23 ',\n",
       " '531 ',\n",
       " '4601 ',\n",
       " '267 ',\n",
       " '267 ',\n",
       " '76 ',\n",
       " ' ',\n",
       " '1000 ',\n",
       " '151 ',\n",
       " '958 ',\n",
       " '7200 ',\n",
       " '10 ',\n",
       " '285 ',\n",
       " '435 ',\n",
       " '527 ',\n",
       " '5000 ',\n",
       " '5000 ',\n",
       " '178 ',\n",
       " '1484 ',\n",
       " '101 ',\n",
       " ' ',\n",
       " '20000 ',\n",
       " '6650 ',\n",
       " '2565 ',\n",
       " '2458285 ',\n",
       " '299285 ',\n",
       " '340 ',\n",
       " '68040 ',\n",
       " ' ',\n",
       " '122 ',\n",
       " '178080 ',\n",
       " '50672 ',\n",
       " '640 ',\n",
       " '9000 ',\n",
       " '10104 ',\n",
       " '256932 ',\n",
       " '640 ',\n",
       " '191779 ',\n",
       " '4000000 ',\n",
       " ' ',\n",
       " '10000 ',\n",
       " '989818 ',\n",
       " '129000 ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " '21578 ',\n",
       " '463 ',\n",
       " '600 ',\n",
       " '332 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '690 ',\n",
       " '1000 ',\n",
       " '270 ',\n",
       " '6435 ',\n",
       " '2310 ',\n",
       " '58000 ',\n",
       " '946 ',\n",
       " '20008 ',\n",
       " '208 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1024 ',\n",
       " '10080 ',\n",
       " '50400 ',\n",
       " '1025010 ',\n",
       " '19020 ',\n",
       " '1364 ',\n",
       " '961 ',\n",
       " '517 ',\n",
       " '200 ',\n",
       " '8000000 ',\n",
       " '1030 ',\n",
       " '606 ',\n",
       " '900 ',\n",
       " '2600 ',\n",
       " '1950 ',\n",
       " '13500 ',\n",
       " '4400 ',\n",
       " '2536 ',\n",
       " '300 ',\n",
       " '197 ',\n",
       " '2858 ',\n",
       " '748 ',\n",
       " '11640 ',\n",
       " '1593 ',\n",
       " '1567 ',\n",
       " '22632 ',\n",
       " '360 ',\n",
       " '103 ',\n",
       " '1994 ',\n",
       " '120 ',\n",
       " '4898 ',\n",
       " '2396130 ',\n",
       " '16772 ',\n",
       " '5875 ',\n",
       " '503 ',\n",
       " '51 ',\n",
       " '106 ',\n",
       " '2126 ',\n",
       " '5456 ',\n",
       " '8800 ',\n",
       " '164860 ',\n",
       " ' ',\n",
       " '1941 ',\n",
       " '130065 ',\n",
       " '515345 ',\n",
       " '440 ',\n",
       " ' ',\n",
       " '53500 ',\n",
       " '8235 ',\n",
       " ' ',\n",
       " '5749132 ',\n",
       " '2215 ',\n",
       " '310 ',\n",
       " '10000 ',\n",
       " '3000 ',\n",
       " '1500 ',\n",
       " '30000 ',\n",
       " '2500 ',\n",
       " '4143 ',\n",
       " '64 ',\n",
       " '53414 ',\n",
       " '65554 ',\n",
       " '45211 ',\n",
       " '1138562 ',\n",
       " '13910 ',\n",
       " '583 ',\n",
       " '2551 ',\n",
       " '34465 ',\n",
       " '5574 ',\n",
       " '245057 ',\n",
       " '182 ',\n",
       " '3850505 ',\n",
       " '138 ',\n",
       " '1080 ',\n",
       " '2075259 ',\n",
       " '210 ',\n",
       " '115 ',\n",
       " '3960456 ',\n",
       " ' ',\n",
       " '10299 ',\n",
       " '1600 ',\n",
       " '768 ',\n",
       " '308 ',\n",
       " '100 ',\n",
       " '237 ',\n",
       " '434874 ',\n",
       " '536 ',\n",
       " '140000 ',\n",
       " '6118 ',\n",
       " '165632 ',\n",
       " '18000 ',\n",
       " '540 ',\n",
       " '931 ',\n",
       " '1055 ',\n",
       " '100 ',\n",
       " '9120 ',\n",
       " '403 ',\n",
       " '111740 ',\n",
       " '10421 ',\n",
       " '5820 ',\n",
       " '403 ',\n",
       " '14980 ',\n",
       " '45730 ',\n",
       " '2584 ',\n",
       " '1372 ',\n",
       " '306 ',\n",
       " '120000 ',\n",
       " '13910 ',\n",
       " '2747 ',\n",
       " '3395 ',\n",
       " '39242 ',\n",
       " '4137 ',\n",
       " '17389 ',\n",
       " '51 ',\n",
       " '470 ',\n",
       " '132 ',\n",
       " '5000000 ',\n",
       " '11000000 ',\n",
       " '250 ',\n",
       " '126 ',\n",
       " ' ',\n",
       " '4889 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '340 ',\n",
       " '501 ',\n",
       " '45781 ',\n",
       " '1503 ',\n",
       " '440 ',\n",
       " '2000 ',\n",
       " '9568 ',\n",
       " '168 ']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_types</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Statlog Project</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Student Loan Relational</td>\n",
       "      <td>Domain-Theory</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1000</td>\n",
       "      <td></td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Teaching Assistant Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tic-Tac-Toe Endgame</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>958</td>\n",
       "      <td>9</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Thyroid Disease</td>\n",
       "      <td>Multivariate, Domain-Theory</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Real</td>\n",
       "      <td>7200</td>\n",
       "      <td>21</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name                          Type  \\\n",
       "0                         Abalone                 Multivariate    \n",
       "1                           Adult                 Multivariate    \n",
       "2                       Annealing                 Multivariate    \n",
       "3    Anonymous Microsoft Web Data                                 \n",
       "4                      Arrhythmia                 Multivariate    \n",
       "..                            ...                           ...   \n",
       "95                Statlog Project                                 \n",
       "96        Student Loan Relational                Domain-Theory    \n",
       "97  Teaching Assistant Evaluation                 Multivariate    \n",
       "98            Tic-Tac-Toe Endgame                 Multivariate    \n",
       "99                Thyroid Disease  Multivariate, Domain-Theory    \n",
       "\n",
       "                    Task              Attribute_types No_of_instances  \\\n",
       "0        Classification   Categorical, Integer, Real            4177    \n",
       "1        Classification         Categorical, Integer           48842    \n",
       "2        Classification   Categorical, Integer, Real             798    \n",
       "3   Recommender-Systems                  Categorical           37711    \n",
       "4        Classification   Categorical, Integer, Real             452    \n",
       "..                   ...                          ...             ...   \n",
       "95                                                                      \n",
       "96                                                              1000    \n",
       "97       Classification         Categorical, Integer             151    \n",
       "98       Classification                  Categorical             958    \n",
       "99       Classification            Categorical, Real            7200    \n",
       "\n",
       "   No_of_Attributes   Year  \n",
       "0                8   1995   \n",
       "1               14   1996   \n",
       "2               38          \n",
       "3              294   1998   \n",
       "4              279   1998   \n",
       "..              ...    ...  \n",
       "95                   1992   \n",
       "96                   1993   \n",
       "97               5   1997   \n",
       "98               9   1991   \n",
       "99              21   1987   \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Name']=name[:100]\n",
    "df['Type']=Type[:100]\n",
    "df['Task']=task[:100]\n",
    "df['Attribute_types']=attri_t[:100]\n",
    "df['No_of_instances']=inst[:100]\n",
    "df['No_of_Attributes']=attri[:100]\n",
    "df['Year']=year[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DONE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
